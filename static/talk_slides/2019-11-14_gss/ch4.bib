
@article{Carpenter2017,
  title = {Stan: {{A}} Probabilistic Programming Language},
  issn = {1548-7660},
  abstract = {Stan is a probabilistic programming language for specifying statistical models. A Stan program imperatively defines a log probability function over parameters conditioned on specified data and constants. As of version 2.2.0, Stan provides full Bayesian inference for continuous-variable models through Markov chain Monte Carlo methods such as the No-U-Turn sampler, an adaptive form of Hamiltonian Monte Carlo sampling. Penalized maximum likelihood estimates are calculated using optimization methods such as the Broyden-Fletcher-Goldfarb-Shanno algorithm. Stan is also a platform for computing log densities and their gradients and Hessians, which can be used in alternative algorithms such as variational Bayes, expectation propa- gation, and marginal inference using approximate integration. To this end, Stan is set up so that the densities, gradients, and Hessians, along with intermediate quantities of the algorithm such as acceptance probabilities, are easily accessible. Stan can be called from the command line, through R using the RStan package, or through Python using the PyStan package. All three interfaces support sampling or optimization-based inference and analysis, and RStan and PyStan also provide access to log probabilities, gradients, Hessians, and data I/O.},
  journal = {J. Stat. Softw.},
  doi = {10.18637/jss.v076.i01},
  author = {Carpenter, Bob and Gelman, Andrew and Hoffman, Matthew D and Lee, Daniel and Goodrich, Ben and Betancourt, Michael and Brubaker, Marcus and Guo, Jiqiang and Li, Peter and Riddell, Allen},
  year = {2017},
  file = {/home/jkbest/Dropbox/Zotero/storage/QYVEMI42/Carpenter et al. - 2017 - Stan.pdf}
}

@article{GirolamiCalderhead2011,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {0907.1100},
  title = {Riemann Manifold {{Langevin}} and {{Hamiltonian Monte Carlo}} Methods},
  volume = {73},
  issn = {13697412},
  abstract = {The paper proposes Metropolis adjusted Langevin and Hamiltonian Monte Carlo sampling methods defined on the Riemann manifold to resolve the shortcomings of existing Monte Carlo algorithms when sampling from target densities that may be high dimensional and exhibit strong correlations. The methods provide fully automated adaptation mechanisms that circumvent the costly pilot runs that are required to tune proposal densities for Metropolis-Hastings or indeed Hamiltonian Monte Carlo and Metropolis adjusted Langevin algorithms. This allows for highly efficient sampling even in very high dimensions where different scalings may be required for the transient and stationary phases of the Markov chain. The methodology proposed exploits the Riemann geometry of the parameter space of statistical models and thus automatically adapts to the local structure when simulating paths across this manifold, providing highly efficient convergence and exploration of the target density. The performance of these Riemann manifold Monte Carlo methods is rigorously assessed by performing inference on logistic regression models, log-Gaussian Cox point processes, stochastic volatility models and Bayesian estimation of dynamic systems described by non-linear differential equations. Substantial improvements in the time-normalized effective sample size are reported when compared with alternative sampling approaches. MATLAB code that is available from http://www.ucl.ac.uk/statistics/research/rmhmc allows replication of all the results reported.},
  number = {2},
  journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
  doi = {10.1111/j.1467-9868.2010.00765.x},
  author = {Girolami, Mark and Calderhead, Ben},
  month = mar,
  year = {2011},
  keywords = {Bayesian inference,Geometry in statistics,Langevin diffusion,Markov chain Monte Carlo methods,Riemann manifolds,riemannian hmc,MCMC,Hamiltonian Monte Carlo},
  pages = {123-214},
  file = {/home/jkbest/Dropbox/Zotero/storage/BF3LH4EZ/Girolami and Calderhead - 2011 - Riemann manifold Langevin and Hamiltonian Monte Carlo methods.pdf}
}

@article{MaunderPrager2003,
  title = {Is It Time to Discard the {{Schaefer}} Model from the Stock Assessment Scientist's Toolbox?},
  volume = {61},
  issn = {01657836},
  number = {1-3},
  journal = {Fish. Res.},
  doi = {10.1016/S0165-7836(02)00273-4},
  author = {Maunder, Mark N. and Prager, Michael H.},
  year = {2003},
  pages = {145-154},
  file = {/home/jkbest/Dropbox/Zotero/storage/9FICDJBI/Maunder and Prager - 2003 - Is it time to discard the Schaefer model from the stock assessment scientist's.pdf}
}

@article{CressieEtAl2009,
  title = {Accounting for Uncertainty in Ecological Analysis: The Strengths and Limitations of Hierarchical Statistical Modeling},
  volume = {19},
  issn = {1051-0761},
  number = {3},
  journal = {Ecol. Appl.},
  doi = {10.1890/07-0744.1},
  author = {Cressie, Noel A. C. and Calder, Catherine A. and Clark, James S. and Ver Hoef, Jay M. and Wikle, Christopher K.},
  month = apr,
  year = {2009},
  keywords = {Bayesian modeling,data model,design,empirical Bayes,harbor seals,MCMC,prior,process model,spatial process,spatiotemporal process},
  pages = {553-570},
  file = {/home/jkbest/Dropbox/Zotero/storage/QNGRHD9E/Cressie et al. - 2009 - Accounting for uncertainty in ecological analysis.pdf}
}

@article{Papaspiliopoulos2007,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {0708.3797},
  title = {A General Framework for the Parametrization of Hierarchical Models},
  volume = {22},
  issn = {0883-4237},
  abstract = {In this paper, we describe centering and noncentering methodology as complementary techniques for use in parametrization of broad classes of hierarchical models, with a view to the construction of effective MCMC algorithms for exploring posterior distributions from these models. We give a clear qualitative understanding as to when centering and noncentering work well, and introduce theory concerning the convergence time complexity of Gibbs samplers using centered and noncentered parametrizations. We give general recipes for the construction of noncentered parametrizations, including an auxiliary variable technique called the state-space expansion technique. We also describe partially noncentered methods, and demonstrate their use in constructing robust Gibbs sampler algorithms whose convergence properties are not overly sensitive to the data.},
  number = {1},
  journal = {Stat. Sci.},
  doi = {10.1214/088342307000000014},
  author = {Papaspiliopoulos, Omiros and Roberts, Gareth O. and Sk{\"o}ld, Martin},
  year = {2007},
  keywords = {MCMC,hierarchical models,chastic processes,latent sto,parametrization},
  pages = {59-73},
  file = {/home/jkbest/Dropbox/Zotero/storage/9LABV9M2/Papaspiliopoulos et al. - 2007 - A general framework for the parametrization of hierarchical models.pdf;/home/jkbest/Dropbox/Zotero/storage/IGEHAE88/Papaspiliopoulos et al. - 2007 - A general framework for the parametrization of hierarchical models.pdf}
}

@incollection{BetancourtGirolami2015,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1312.0906},
  address = {{Boca Raton, FL}},
  title = {Hamiltonian {{Monte Carlo}} for Hierarchical Models},
  isbn = {9761482235111},
  abstract = {Hierarchical modeling provides a framework for modeling the complex interactions typical of problems in applied statistics. By capturing these relationships, however, hierarchical models also introduce distinctive pathologies that quickly limit the efficiency of most common methods of in- ference. In this paper we explore the use of Hamiltonian Monte Carlo for hierarchical models and demonstrate how the algorithm can overcome those pathologies in practical applications.},
  booktitle = {Current {{Trends}} in {{Bayesian Methodology}} with {{Applications}}},
  publisher = {{CRC press}},
  author = {Betancourt, M. J. and Girolami, Mark},
  editor = {Upadhyay, Satyanshu Kumar and Singh, Umesh and Dey, Dipak K. and Loganathan, Appaia},
  year = {2015},
  pages = {79-101},
  file = {/home/jkbest/Dropbox/Zotero/storage/AGA3HHDT/Betancourt and Girolami - 2015 - Hamiltonian Monte Carlo for hierarchical models.pdf},
  doi = {10.1201/b18502-5}
}

@article{AeberhardEtAl2018,
  title = {Review of State-Space Models for Fisheries Science},
  volume = {5},
  issn = {2326-8298},
  abstract = {Fisheries science is concerned with the management and understanding of the raising and harvesting of fish. Fish stocks are assessed using biological and fisheries data with the goal of estimating either their total population or biomass. Stock assessment models also make it possible to predict how stocks will respond to varying levels of fishing pressure in the future. Such tools are essential with overfishing now reducing stocks and employment worldwide, with in turn many serious social, economic, and environmental implications. Increasingly, a state-space framework is being used in place of deterministic and standard parametric stock assessment models. These efforts have not only had considerable impact on fisheries management but have also advanced the supporting statistical theory and inference tools as well as the required software. An application of such techniques to the North Sea cod stock highlights what should be considered best practices for science-based fisheries management.},
  number = {1},
  journal = {Annu. Rev. Stat. Appl.},
  doi = {10.1146/annurev-statistics-031017-100427},
  author = {Aeberhard, William H. and Mills Flemming, Joanna and Nielsen, Anders},
  month = mar,
  year = {2018},
  keywords = {population dynamics,state space models,fisheries,stock assessment,fish stock assessment,random effects prediction,state-space assessment model},
  pages = {215-235},
  file = {/home/jkbest/Dropbox/Zotero/storage/K7XTFKIA/Aeberhard et al. - 2018 - Review of state-space models for fisheries science.pdf}
}

@article{Winker2018,
  title = {{{JABBA}}: {{Just Another Bayesian Biomass Assessment}}},
  volume = {204},
  issn = {01657836},
  abstract = {This study presents a new, open-source modelling software entitled `Just Another Bayesian Biomass Assessment' (JABBA). JABBA can be used for biomass dynamic stock assessment applications, and has emerged from the development of a Bayesian State-Space Surplus Production Model framework, already applied in stock assessments of sharks, tuna, and billfishes around the world. JABBA presents a unifying, flexible framework for biomass dynamic modelling, runs quickly, and generates reproducible stock status estimates and diagnostic tools. Specific emphasis has been placed on flexibility for specifying alternative scenarios, achieving high stability and improved convergence rates. Default JABBA features include: 1) an integrated state-space tool for averaging and automatically fitting multiple catch per unit effort (CPUE) time series; 2) data-weighting through estimation of additional observation variance for individual or grouped CPUE; 3) selection of Fox, Schaefer, or Pella-Tomlinson production functions; 4) options to fix or estimate process and observation variance components; 5) model diagnostic tools; 6) future projections for alternative catch regimes; and 7) a suite of inbuilt graphics illustrating model fit diagnostics and stock status results. As a case study, JABBA is applied to the 2017 assessment input data for South Atlantic swordfish (Xiphias gladius). We envision that JABBA will become a widely used, open-source stock assessment tool, readily improved and modified by the global scientific community.},
  language = {en},
  number = {November 2017},
  journal = {Fish. Res.},
  doi = {10.1016/j.fishres.2018.03.010},
  author = {Winker, Henning and Carvalho, Felipe and Kapur, Maia},
  month = aug,
  year = {2018},
  keywords = {Bayesian,JAGS,State-space framework,Stock assessment,Surplus production model},
  pages = {275-288},
  file = {/home/jkbest/Dropbox/Zotero/storage/4AL26ZEI/Winker et al. - 2018 - JABBA.pdf}
}

@article{Meyer1999,
  title = {{{BUGS}} in {{Bayesian}} Stock Assessments},
  volume = {56},
  issn = {0706-652X},
  abstract = {This paper illustrates the ease with which Bayesian nonlinear state\textendash{}space models can now be used for practical fisheries stock assessment. Sampling from the joint posterior density is accomplished using Gibbs sampling via BUGS, a freely available software package. By taking advantage of the model representation as a directed acyclic graph, BUGS automates the hitherto tedious calculation of the full conditional posterior distributions. Moreover, the output from BUGS can be read directly into the software CODA for convergence diagnostics and statistical summary. We illustrate the BUGS implementation of a nonlinear nonnormal state\textendash{}space model using a Schaefer surplus production model as a basic example. This approach extends to other assessment methodologies, including delay difference and age-structured models.},
  number = {6},
  journal = {Can. J. Fish. Aquat. Sci.},
  doi = {10.1139/f99-043},
  author = {Meyer, Renate and Millar, Russell B.},
  month = jun,
  year = {1999},
  pages = {1078-1087},
  file = {/home/jkbest/Dropbox/Zotero/storage/KJZ33GEI/Meyer and Millar - 1999 - BUGS in Bayesian stock assessments.pdf;/home/jkbest/Dropbox/Zotero/storage/ZKTKFPAT/Meyer and Millar - 1999 - BUGS in Bayesian stock assessments.pdf},
  pmid = {4549946}
}

@article{Millar2000,
  title = {Non-Linear State Space Modelling of Fisheries Biomass Dynamics by Using {{Metropolis}}-{{Hastings}} within-{{Gibbs}} Sampling},
  volume = {49},
  issn = {0035-9254},
  abstract = {State space modelling and Bayesian analysis are both active areas of applied research in fisheries stock assessment. Combining these two methodologies facilitates the fitting of state space models that may be non-linear and have non-normal errors, and hence it is particularl y useful for modelling fisheries dynamics. Here, this approach is demonstrated by fitting a non-linear surplus production model to data on South Atlantic albacore tuna (Thunnus alalunga). The state space approach allows for random variability in both the data (the measurement of relative biomass) and in annual biomass dynamics of the tuna stock. Sampling from the joint posterior distribution of the unobservables was achieved by using Metropolis-Hastings within-Gibbs sampling.},
  language = {en},
  number = {3},
  journal = {J. Royal Stat. Soc. C},
  doi = {10.1111/1467-9876.00195},
  author = {Millar, Russell B. and Meyer, Renate},
  month = aug,
  year = {2000},
  keywords = {Markov chain Monte Carlo sampling,Bayesian analysis,Fish stock assessment,Non‐linear state space models,Surplus production models,Tuna},
  pages = {327-342},
  file = {/home/jkbest/Dropbox/Zotero/storage/ZMW58IR9/Millar and Meyer - 2000 - Non-linear state space modelling of fisheries biomass dynamics by using.pdf}
}

@article{Schaefer1954,
  title = {Some Aspect of the Dynamics of Populations Important to the Management of the Commercial Marine Fisheries},
  volume = {1},
  issn = {1098-6596},
  number = {2},
  journal = {Inter-Am. Trop. Tuna Comm. Bull.},
  doi = {10.1017/CBO9781107415324.004},
  author = {Schaefer, Milner B},
  year = {1954},
  keywords = {Fish Population,Fishing Effort,Natural Rate,Singular Point,Stable Equilibrium},
  pages = {27-56},
  file = {/home/jkbest/Dropbox/Zotero/storage/L3KPL3FC/Schaefer - 1954 - Some aspect of the dynamics of populations important to the management of the.pdf;/home/jkbest/Dropbox/Zotero/storage/NPIRR464/Schaefer - 1954 - Some aspect of the dynamics of populations important to the management of the.pdf},
  pmid = {25246403}
}

@article{Monnahan2018,
  title = {No-{{U}}-Turn Sampling for Fast {{Bayesian}} Inference in {{ADMB}} and {{TMB}}: {{Introducing}} the Adnuts and Tmbstan {{R}} Packages},
  volume = {13},
  issn = {1932-6203},
  abstract = {Statistical inference is a widely-used, powerful tool for learning about natural processes in diverse fields. The statistical software platforms AD Model Builder (ADMB) and Template Model Builder (TMB) are particularly popular in the ecological literature, where they are typically used to perform frequentist inference of complex models. However, both lack capabilities for flexible and efficient Markov chain Monte Carlo (MCMC) integration. Recently, the no-U-turn sampler (NUTS) MCMC algorithm has gained popularity for Bayesian inference through the software Stan because it is efficient for high dimensional, complex hierarchical models. Here, we introduce the R packages adnuts and tmbstan, which provide NUTS sampling in parallel and interactive diagnostics with ShinyStan. The ADMB source code was modified to provide NUTS, while TMB models are linked directly into Stan. We describe the packages, provide case studies demonstrating their use, and contrast performance against Stan. For TMB models, we show how to test the accuracy of the Laplace approximation using NUTS. For complex models, the performance of ADMB and TMB was typically within +/- 50\% the speed of Stan. In one TMB case study we found inaccuracies in the Laplace approximation, potentially leading to biased inference. adnuts provides a new method for estimating hierarchical ADMB models which previously were infeasible. TMB users can fit the same model in both frequentist and Bayesian paradigms, including using NUTS to test the validity of the Laplace approximation of the marginal likelihood for arbitrary subsets of parameters. These software developments extend the available statistical methods of the ADMB and TMB user base with no additional effort by the user.},
  number = {5},
  journal = {PLOS ONE},
  doi = {10.1371/journal.pone.0197954},
  author = {Monnahan, Cole C. and Kristensen, Kasper},
  editor = {Deng, Yong},
  month = may,
  year = {2018},
  pages = {e0197954},
  file = {/home/jkbest/Dropbox/Zotero/storage/IX7ZM66S/Monnahan and Kristensen - 2018 - No-U-turn sampling for fast Bayesian inference in ADMB and TMB.pdf}
}

@article{BolkerEtAl2013,
  title = {Strategies for Fitting Nonlinear Ecological Models in {{R}}, {{AD Model Builder}}, and {{BUGS}}},
  volume = {4},
  issn = {2041210X},
  number = {6},
  journal = {Methods Ecol. Evol.},
  doi = {10.1111/2041-210X.12044},
  author = {Bolker, Benjamin M. and Gardner, Beth and Maunder, Mark and Berg, Casper W. and Brooks, Mollie and Comita, Liza and Crone, Elizabeth and Cubaynes, Sarah and Davies, Trevor and {de Valpine}, Perry and Ford, Jessica and Gimenez, Olivier and K{\'e}ry, Marc and Kim, Eun Jung and {Lennert-Cody}, Cleridy and Magnusson, Arni and Martell, Steve and Nash, John and Nielsen, Anders and Regetz, Jim and Skaug, Hans and Zipkin, Elise F.},
  editor = {Ramula, Satu},
  month = jun,
  year = {2013},
  keywords = {R,JAGS,AD Model Builder,optimization,parameter estimation,WinBUGS},
  pages = {501-512},
  file = {/home/jkbest/Dropbox/Zotero/storage/P5FYQBBX/Bolker et al. - 2013 - Strategies for fitting nonlinear ecological models in R, AD Model Builder, and.pdf}
}

@article{Monnahan2017,
  title = {Faster Estimation of {{Bayesian}} Models in Ecology Using {{Hamiltonian Monte Carlo}}},
  volume = {8},
  issn = {2041210X},
  abstract = {Despite the potential of HMC, and the availability of Stan, adoption has been slow in ecology, likely because ecologists are either unaware of its existence, or are unsure when it should be preferred over BUGS. Here, we illustrate the principles that underlie HMC and then compare the efficiency between Stan and a BUGS variant, JAGS (Plummer 2003), across a range of models in population ecology. Specifically, we test how HMC performance scales with model size and complexity, and its suitability for hierarchical models. Our goal is to explore the relative benefits of Stan and JAGS and to provide guidance for ecologists looking to use the power of HMC for faster and more robust Bayesian inference. Stan is faster than JAGS.},
  language = {en},
  number = {3},
  journal = {Methods Ecol. Evol.},
  doi = {10.1111/2041-210X.12681},
  author = {Monnahan, Cole C. and Thorson, James T. and Branch, Trevor A.},
  editor = {O'Hara, Robert B.},
  month = mar,
  year = {2017},
  pages = {339-348},
  file = {/home/jkbest/Dropbox/Zotero/storage/YPL4DYSW/Monnahan et al. - 2017 - Faster estimation of Bayesian models in ecology using Hamiltonian Monte Carlo.pdf}
}

@article{Kleppe2018,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1806.02068},
  primaryClass = {stat},
  title = {Dynamically Rescaled {{Hamiltonian Monte Carlo}} for {{Bayesian Hierarchical Models}}},
  abstract = {Dynamically rescaled Hamiltonian Monte Carlo (DRHMC) is introduced as a computationally fast and easily implemented method for performing full Bayesian analysis in hierarchical statistical models. The method relies on introducing a modified parameterisation so that the re-parameterised target distribution has close to constant scaling properties, and thus is easily sampled using standard (Euclidian metric) Hamiltonian Monte Carlo. Provided that the parameterisations of the conditional distributions specifying the hierarchical model are ``constant information parameterisations'' (CIP), the relation between the modified- and original parameterisation is bijective, explicitly computed and admit exploitation of sparsity in the numerical linear algebra involved. CIPs for a large catalogue of statistical models are presented, and from the catalogue, it is clear that many CIPs are currently routinely used in statistical computing. A relation between the proposed methodology and a class of explicitly integrated Riemann manifold Hamiltonian Monte Carlo methods is discussed. The methodology is illustrated on several example models, including a model for inflation rates with multiple levels of non-linearly dependent latent variables.},
  language = {en},
  journal = {arXiv},
  author = {Kleppe, Tore Selland},
  month = jun,
  year = {2018},
  keywords = {Statistics - Methodology,Statistics - Computation,⛔ No DOI found},
  file = {/home/jkbest/Dropbox/Zotero/storage/EV4JAXW7/Kleppe - 2018 - Dynamically rescaled Hamiltonian Monte Carlo for Bayesian Hierarchical Models.pdf;/home/jkbest/Dropbox/Zotero/storage/IBKL2PMA/Kleppe - 2018 - Dynamically rescaled Hamiltonian Monte Carlo for Bayesian Hierarchical Models.pdf}
}

@article{WaltersLudwig1994,
  title = {Calculation of {{Bayes}} Posterior Probability Distributions for Key Population Parameters},
  volume = {51},
  issn = {0706-652X},
  abstract = {The Bayes posterior probability distribution is a powerful way to represent uncertainty in fisheries stock assessments, and can be calculated for key population and policy parameters of practically any population dynamics model. But the calculation is unwieldy when probabilities are to be assigned to a large grid of parameter combinations. The computational burden can be reduced substantially by analytically integrating over at least two "nuisance parameters" that occur in most assessment models: the observation error variance and the catchability coefficient. This simplification allows the analyst and manager to focus more easily on population parameters (stock size, slope of recruitment curve) that are of direct policy interest., La distribution bay{\'e}sienne de probabilit{\'e} a posteriori constitue un outil puissant pour repr{\'e}senter les incertitudes dans les {\'e}valuations des stocks halieutiques, et peut {\^e}tre calcul{\'e}e pour des param{\`e}tres cl{\'e}s de la population et des politiques dans pratiquement n'importe quel mod{\`e}le de la dynamique des populations. Toutefois, ce calcul est trop compliqu{\'e} lorsqu'il faut attribuer des probabilit{\'e}s {\`a} une large grille de combinaisons de param{\`e}tres. Le fardeau du calcul peut {\^e}tre fortement r{\'e}duit si on fait une int{\'e}gration analytique d'au moins deux param{\`e}tres d{\'e}rangeants qui sont pr{\'e}sents dans la plupart des mod{\`e}les d'{\'e}valuation : la variance de l'erreur d'observation et le coefficient de capturabilit{\'e}. Cette simplification permet {\`a} l'analyste et au gestionnaire de s'int{\'e}resser plus directement aux param{\`e}tres sur les populations (taille du stock, pente de la courbe du recrutement) qui pr{\'e}sentent un int{\'e}r{\^e}t direct pour les politiques.},
  language = {en},
  number = {3},
  journal = {Can. J. Fish. Aquat. Sci.},
  doi = {10.1139/f94-071},
  author = {Walters, Carl and Ludwig, Donald},
  month = mar,
  year = {1994},
  pages = {713-722},
  file = {/home/jkbest/Dropbox/Zotero/storage/AE7TDQH9/Walters and Ludwig - 1994 - Calculation of Bayes posterior probability distrib.pdf;/home/jkbest/Dropbox/Zotero/storage/MWUT8XVU/Walters and Ludwig - 1994 - Calculation of Bayes posterior probability distributions for key population.pdf}
}

@article{Schnute1994,
  title = {A General Framework for Developing Sequential Fisheries Models},
  volume = {51},
  issn = {0706-652X, 1205-7533},
  language = {en},
  number = {8},
  journal = {Can. J. Fish. Aquat. Sci.},
  doi = {10.1139/f94-168},
  author = {Schnute, Jon T.},
  month = aug,
  year = {1994},
  pages = {1676-1688},
  file = {/home/jkbest/Dropbox/Zotero/storage/XP3IBCVZ/Schnute - 1994 - A general framework for developing sequential fisheries models.pdf}
}

@article{Betancourt2017a,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1701.02434},
  primaryClass = {stat},
  title = {A Conceptual Introduction to {{Hamiltonian Monte Carlo}}},
  abstract = {Hamiltonian Monte Carlo has proven a remarkable empirical success, but only recently have we begun to develop a rigorous understanding of why it performs so well on difficult problems and how it is best applied in practice. Unfortunately, that understanding is confined within the mathematics of differential geometry which has limited its dissemination, especially to the applied communities for which it is particularly important.},
  language = {en},
  journal = {arXiv},
  author = {Betancourt, Michael},
  month = jan,
  year = {2017},
  keywords = {Statistics - Methodology,⛔ No DOI found},
  file = {/home/jkbest/Dropbox/Zotero/storage/D8TJFCE9/Betancourt - 2017 - A conceptual introduction to Hamiltonian Monte Carlo.pdf}
}

@book{QuinnDeriso1999,
  address = {{New York}},
  series = {Biological Resource Management Series},
  title = {Quantitative Fish Dynamics},
  isbn = {978-0-19-507631-8},
  lccn = {QL618.3 .Q5 1999},
  language = {en},
  publisher = {{Oxford University Press}},
  author = {Quinn, Terrance J. and Deriso, R. B.},
  year = {1999},
  keywords = {Fish populations,Mathematical models},
  file = {/home/jkbest/Dropbox/Zotero/storage/5ZCTQCSV/Quinn and Deriso - 1999 - Quantitative fish dynamics.pdf}
}

@article{LunnEtAl2000,
  title = {{{WinBUGS}} - a {{Bayesian}} Modelling Framework: Concepts, Structure, and Extensibility},
  volume = {10},
  issn = {1573-1375},
  shorttitle = {{{WinBUGS}} - {{A Bayesian}} Modelling Framework},
  abstract = {WinBUGS is a fully extensible modular framework for constructing and analysing Bayesian full probability models. Models may be specified either textually via the BUGS language or pictorially using a graphical interface called DoodleBUGS. WinBUGS processes the model specification and constructs an object-oriented representation of the model. The software offers a user-interface, based on dialogue boxes and menu commands, through which the model may then be analysed using Markov chain Monte Carlo techniques. In this paper we discuss how and why various modern computing concepts, such as object-orientation and run-time linking, feature in the software's design. We also discuss how the framework may be extended. It is possible to write specific applications that form an apparently seamless interface with WinBUGS for users with specialized requirements. It is also possible to interface with WinBUGS at a lower level by incorporating new object types that may be used by WinBUGS without knowledge of the modules in which they are implemented. Neither of these types of extension require access to, or even recompilation of, the WinBUGS source-code.},
  language = {en},
  number = {4},
  journal = {Stat. Comput.},
  doi = {10.1023/A:1008929526011},
  author = {Lunn, David J. and Thomas, Andrew and Best, Nicky and Spiegelhalter, David},
  month = oct,
  year = {2000},
  keywords = {WinBUGS,BUGS,directed acyclic graphs,Markov chain Monte Carlo,object-orientation,run-time linking,type extension},
  pages = {325-337},
  file = {/home/jkbest/Dropbox/Zotero/storage/P7EUUYEA/Lunn et al. - 2000 - WinBUGS - a Bayesian modelling framework.pdf}
}

@article{deValpine2002,
  title = {Review of Methods for Fitting Time-Series Models with Process and Observation Error and Likelihood Calculations for Nonlinear, Non-{{Gaussian}} State-Space Models},
  volume = {70},
  abstract = {A key challenge for analyzing fisheries time-series data has been to incorporate sources of uncertainty such as process error, observation error, and model-structure uncertainty. Recent years have seen promising advances in methods for handling the first two together in a state-space framework, but likelihood calculations for state-space models require high-dimensional integrals, which make their use computationally challenging. The first section of this paper reviews model-fitting methods that use a state-space model structure, including errors-in-variables methods, Bayesian methods that do and do not use the state-space likelihood, and the possibility of classical likelihood analysis with nonlinear, non-Gaussian state-space models. It also discusses the relationship between true likelihood calculations and errors-in-variables likelihoods, as well as the role of Monte Carlo methods in implementing Bayesian and/or state-space model analyses. The second section introduces a numerical method for calculating state-space likelihoods without Monte Carlo methods and gives examples in a classical maximum-likelihood framework. The method is applicable when the dimension of the state space at each time step is low. Although recent advances in model-fitting and analysis methods are promising, inferences from noisy data and complex processes will continue to be variable and uncertain.},
  language = {en},
  number = {2},
  journal = {Bull. Mar. Sci.},
  author = {{de Valpine}, Perry},
  year = {2002},
  keywords = {⛔ No DOI found},
  pages = {455-471},
  file = {/home/jkbest/Dropbox/Zotero/storage/3CA9FLI6/de Valpine - 2002 - Review of methods for fitting time-series models w.pdf}
}

@article{Fox1970,
  title = {An Exponential Surplus-Yield Model for Optimizing Exploited Fish Populations},
  volume = {99},
  copyright = {\textcopyright{} 1970 American Fisheries Society},
  issn = {1548-8659},
  abstract = {A surplus-yield model of fishery dynamics which assumes the Gompertz growth function is developed, resulting in an implied exponential relationship between catch per unit effort and fishing effort, and in an asymmetrical yield curve. A maximum sustainable yield, predicted by the exponential model, is obtained from a population size which is about 37\% of the environmentally limited maximum size. Three methods for estimating the parameters of the exponential model, adapted from those used for the linear model of Schaefer (1954, 1957), are presented. The exponential model is compared with the linear model using examples of the fisheries for the California sardine, Sardinops caerulea (Girard), and yellowfin tuna, Thunnus albacares (Bonnaterre) of the eastern tropical Pacific and western Atlantic Oceans. Management implications are discussed.},
  language = {en},
  number = {1},
  journal = {Trans. Am. Fish. Soc.},
  doi = {10.1577/1548-8659(1970)99<80:AESMFO>2.0.CO;2},
  author = {Fox, William W.},
  month = jan,
  year = {1970},
  keywords = {Surplus production model},
  pages = {80-88},
  file = {/home/jkbest/Dropbox/Zotero/storage/VMU9RAJE/Fox - 1970 - An exponential surplus-yield model for optimizing exploited fish populations.pdf}
}

@article{OnoEtAl2012,
  title = {Model Performance Analysis for {{Bayesian}} Biomass Dynamics Models Using Bias, Precision and Reliability Metrics},
  volume = {125-126},
  issn = {0165-7836},
  abstract = {Bayesian observation error (OEM), process error (PEM) and state-space (SSM) implementations of a Fox biomass dynamics model are compared using a simulation\textendash{}estimation approach and by applying them to data for the octopus fishery off Mauritania. Estimation performance is evaluated in terms of bias, precision, and reliability measured by the extreme tail-area probability and the mean highest posterior density interval. The PEM generally performs poorest of the three methods in terms of the these performance metrics. In contrast, the OEM is precise, but under-represents uncertainty. The OEM is outperformed by the SSM in terms of its ability to provide posterior distributions which adequately capture parameter uncertainty. It is key to consider the above four metrics when comparing estimation performance in a Bayesian context. Finally, although model performance measures are useful, there is still a need to examine goodness of fit statistics in actual applications.},
  journal = {Fish. Res.},
  doi = {10.1016/j.fishres.2012.02.022},
  author = {Ono, Kotaro and Punt, Andr{\'e} E. and Rivot, Etienne},
  month = aug,
  year = {2012},
  keywords = {Bayesian,Model performance,Octopus,OpenBUGS,State-space model},
  pages = {173-183},
  file = {/home/jkbest/Dropbox/Zotero/storage/3ENTNXNC/Ono et al. - 2012 - Model performance analysis for Bayesian biomass dynamics models using bias,.pdf}
}

@article{MontenegroBranco2016,
  title = {Bayesian State-Space Approach to Biomass Dynamic Models with Skewed and Heavy-Tailed Error Distributions},
  volume = {181},
  issn = {0165-7836},
  abstract = {We use the state-space approach to the logistic population growth model to update our knowledge of a population of marine shrimp off the Chilean coast. The unobserved state is the annual shrimp biomass, and the observation is the mean catch per unit effort. The observation equation is linear, and the state equation is nonlinear. The models include normal, student-t, skew-normal, and skew-t distributions for additive observation errors; and log-normal, log-t, log-skew-normal, and log-skew-t distributions for multiplicative observation errors. We use Bayesian approach to obtain inference, and the posterior distributions are approximated using Markov chain Monte Carlo methods. Deviance Information Criteria are lower in models considering log-skew-normal and log-skew-t observation errors. Furthermore, considering the posterior predictive distributions of the autocorrelations of the observation errors, these two models work best for the analyzed data set.},
  journal = {Fish. Res.},
  doi = {10.1016/j.fishres.2016.03.021},
  author = {Montenegro, Carlos and Branco, M{\'a}rcia},
  month = sep,
  year = {2016},
  keywords = {State-space models,Surplus production model,Bayesian MCMC,Chilean shrimp,Logistic growth model,Nonlinear dynamic models},
  pages = {48-62},
  file = {/home/jkbest/Dropbox/Zotero/storage/MKKLLCZQ/Montenegro and Branco - 2016 - Bayesian state-space approach to biomass dynamic models with skewed and.pdf}
}

@article{deValpineHastings2002,
  title = {Fitting Population Models Incorporating Process Noise and Observation Error},
  volume = {72},
  copyright = {\textcopyright{} 2002 by the Ecological Society of America},
  issn = {1557-7015},
  abstract = {We evaluate a method for fitting models to time series of population abundances that incorporates both process noise and observation error in a likelihood framework. The method follows the probability logic of the Kalman filter, but whereas the Kalman filter applies to linear, Gaussian systems, we implement the full probability calculations numerically so that any nonlinear, non-Gaussian model can be used. We refer to the method as the ``numerically integrated state-space (NISS) method'' and compare it to two common methods used to analyze nonlinear time series in ecology: least squares with only process noise (LSPN) and least squares with only observation error (LSOE). We compare all three methods by fitting Beverton-Holt and Ricker models to many replicate model-generated time series of length 20 with several parameter choices. For the Ricker model we chose parameters for which the deterministic part of the model produces a stable equilibrium, a two-cycle, or a four-cycle. For each set of parameters we used three process-noise and observation-error scenarios: large standard deviation (0.2) for both, and large for one but small (0.05) for the other. The NISS method had lower estimator bias and variance than the other methods in nearly all cases. The only exceptions were for the Ricker model with stable-equilibrium parameters, in which case the LSPN and LSOE methods has lower bias when noise variances most closely met their assumptions. For the Beverton-Holt model, the NISS method was much less biased and more precise than the other methods. We also evaluated the utility of each method for model selection by fitting simulated data to both models and using information criteria for selection. The NISS and LSOE methods showed a strong bias toward selecting the Ricker over the Beverton-Holt, even when data were generated with the Beverton-Holt. It remains unclear whether the LSPN method is generally superior for model selection or has fortuitously better biases in this particular case. These results suggest that information criteria are best used with caution for nonlinear population models with short time series. Finally we evaluated the convergence of likelihood ratios to theoretical asymptotic distributions. Agreement with asymptotic distributions was very good for stable-point Ricker parameters, less accurate for two-cycle and four-cycle Ricker parameters, and least accurate for the Beverton-Holt model. The numerically integrated state-space method has a number of advantages over least squares methods and offers a useful tool for connecting models and data and ecology.},
  language = {en},
  number = {1},
  journal = {Ecol. Monogr.},
  doi = {10.1890/0012-9615(2002)072[0057:FPMIPN]2.0.CO;2},
  author = {{de Valpine}, Perry and Hastings, Alan},
  month = feb,
  year = {2002},
  keywords = {Ricker model,parameter estimation,time series,Beverton-Holt model,Kalman filter,least-squares cf. state-space models,model-fitting,observation error,population models,process noise},
  pages = {57-76},
  file = {/home/jkbest/Dropbox/Zotero/storage/QHMGWVD6/de Valpine and Hastings - 2002 - Fitting population models incorporating process no.pdf}
}

@article{Schnute1977,
  title = {Improved Estimates from the {{Schaefer}} Production Model: Theoretical Considerations},
  volume = {34},
  issn = {0015-296X},
  shorttitle = {Improved {{Estimates}} from the {{Schaefer Production Model}}},
  abstract = {The Schaefer production model is converted to a form directly applicable to a data stream of annual fishing efforts and catches. The new version is also stochastic; that is, it allows for unpredictable influences on the fishery. A new method for estimating optimum effort and catch results from this analysis, as well as a way of measuring uncertainty in these estimates. Equations are given for predicting the next annual catch and assigning confidence limits to this prediction. Linear and nonlinear regressions are proposed for this analysis, and the relationship between them is rigorously demonstrated. The linear method leads to estimation formulas simple enough to be applied on a programmable pocket calculator. Key words: Schaefer model, production model, stochastic model, management, fishing effort, catch per unit effort, maximum sustainable yield, Le mod{\`e}le de production de Schaefer est modifi{\'e} de fa{\c c}on {\`a} {\^e}tre directement applicable {\`a} une s{\'e}rie de donn{\'e}es annuelles sur les efforts de p{\^e}che et sur les prises. La nouvelle version est {\'e}galement stochastique; c'est {\`a} dire qu'il y a place pour les facteurs impr{\'e}visibles influant sur les p{\^e}ches. Il r{\'e}sulte de cette analyse une nouvelle m{\'e}thode d'estimer les r{\'e}sultats optimaux relatifs aux efforts et aux captures ainsi qu'une fa{\c c}on de mesurer l'incertitude reli{\'e}e {\`a} ces estimations. Des {\'e}quations permettent de pr{\'e}voir les captures de l'ann{\'e}e suivante et d'en d{\'e}terminer les limites de confiance. Des r{\'e}gressions lin{\'e}aires et non lin{\'e}aires sont propos{\'e}es pour cette analyse, et la relation entre elles est rigoureusement d{\'e}montr{\'e}e. La m{\'e}thode lin{\'e}aire va de pair avec des formules d'estimation assez simples pour {\^e}tre r{\'e}solues sur une calculette programmable.},
  number = {5},
  journal = {J. Fish. Res. Bd. Can.},
  doi = {10.1139/f77-094},
  author = {Schnute, J.},
  month = may,
  year = {1977},
  pages = {583-603},
  file = {/home/jkbest/Dropbox/Zotero/storage/CL4RD3CV/Schnute - 1977 - Improved estimates from the Schaefer production model.pdf}
}

@article{Punt2003,
  title = {Extending Production Models to Include Process Error in the Population Dynamics},
  volume = {60},
  issn = {0706-652X},
  abstract = {Four methods for fitting production models, including three that account for the effects of error in the population dynamics equation (process error) and when indexing the population (observation error), are evaluated by means of Monte Carlo simulation. An estimator that represents the distributions of biomass explicitly and integrates over the unknown process errors numerically (the NISS estimator) performs best of the four estimators considered, never being the worst estimator and often being the best in terms of the medians of the absolute values of the relative errors. The total-error approach outperforms the observation-error estimator conventionally used to fit dynamic production models, and the performance of a Kalman filter based estimator is particularly poor. Although the NISS estimator is the best-performing estimator considered, its estimates of quantities of management interest are severely biased and highly imprecise for some of the scenarios considered., Une simulation de Monte Carlo permet d'{\'e}valuer quatre m{\'e}thodes d'ajustement des mod{\`e}les de production, dont trois qui prennent en compte les effets des erreurs dans la dynamique de population (erreurs de processus) et dans l'indexation de la population (erreurs d'observation). Des quatre estimateurs examin{\'e}s, l'estimateur NISS, qui repr{\'e}sente la distribution de la biomasse de fa{\c c}on explicite et qui fait num{\'e}riquement l'int{\'e}gration des erreurs de processus inconnues, fonctionne le mieux; il n'est jamais le pire et est tr{\`e}s souvent le meilleur en ce qui concerne les m{\'e}dianes des valeurs absolues des erreurs relatives. La m{\'e}thode de l'erreur totale fonctionne mieux que celle de l'erreur d'observation couramment utilis{\'e}e dans l'ajustement de mod{\`e}les dynamiques de production; la m{\'e}thode qui utilise un filtre de Kalman fonctionne particuli{\`e}rement mal. Bien que la m{\'e}thode NISS soit la meilleure des m{\'e}thodes {\'e}tudi{\'e}es, les estimations d'int{\'e}r{\^e}t pour la gestion qu'elle produit sont particuli{\`e}rement fauss{\'e}es et tr{\`e}s...},
  number = {10},
  journal = {Can. J. Fish. Aquat. Sci.},
  doi = {10.1139/f03-105},
  author = {Punt, Andre E},
  month = oct,
  year = {2003},
  pages = {1217-1228},
  file = {/home/jkbest/Dropbox/Zotero/storage/SCUNPTYV/Punt - 2003 - Extending production models to include process error in the population dynamics.pdf}
}

@article{LudwigWalters1985,
  title = {Are Age-Structured Models Appropriate for Catch-Effort Data?},
  volume = {42},
  issn = {0706-652X},
  abstract = {Simulated data have been used to evaluate the performance of schemes for estimating optimum fishing effort using a simple stock-production model and R. B. Deriso's age-structured model Even when the data are generated using Deriso's model, the simpler production model generally gives as good or better estimates for the optimal effort. The only exception to this result is when data are provided with unrealistically large contrasts in effort and catch per unit effort over time. The implication of these findings is that simple production models should often be used in stock assessments based on catch/effort data, even when more realistic and structurally correct models are available to the analyst; the best choice depends on how much contrast has occurred in the historical effort and catch per unit effort data, rather than on prior knowledge about which model structure is biologically more realistic., Les auteurs ont utilis{\'e} des donn{\'e}es simul{\'e}es pour {\'e}valuer le rendement de plans d'estimation de l'effort de p{\^e}che optimum, {\`a} l'aide d'un simple mod{\`e}le de production de stock et du mod{\`e}le de R. B. Deriso structur{\'e} selon l'{\^a}ge. En g{\'e}n{\'e}ral, le simple mod{\`e}le de production fournit des estimations aussi bonnes, voire meilleures de l'effort optimal m{\^e}me quand les donn{\'e}es sont obtenues du mod{\`e}le de Deriso, avec une seule exception : quand il y a beaucoup trop d'{\'e}cart entre les donn{\'e}es sur l'effort et les prises par unit{\'e} d'effort en fonction du temps. Ces r{\'e}sultats indiquent que de simples mod{\`e}les de production devraient souvent {\^e}tre utilis{\'e}s pour les {\'e}valuations de stock bas{\'e}es sur les donn{\'e}es de prises et d'effort, m{\^e}me quand des mod{\`e}les plus r{\'e}alistes et structurellement corrects sont disponibles; le meilleur choix d{\'e}pend de l'{\'e}cart qui s'est produit dans les donn{\'e}es historiques sur l'effort et les prises par unit{\'e} d'effort et non d'une connaissance ant{\'e}rieure du mod{\`e}le le plus biologiquement r{\'e}aliste.},
  number = {6},
  journal = {Can. J. Fish. Aquat. Sci.},
  doi = {10.1139/f85-132},
  author = {Ludwig, Donald and Walters, Carl J.},
  month = jun,
  year = {1985},
  pages = {1066-1072},
  file = {/home/jkbest/Dropbox/Zotero/storage/85ZHEL3J/Ludwig and Walters - 1985 - Are age-structured models appropriate for catch-effort data.pdf}
}

@article{MillarMeyer2000,
  title = {Bayesian State-Space Modeling of Age-Structured Data: Fitting a Model Is Just the Beginning},
  volume = {57},
  issn = {0706-652X},
  shorttitle = {Bayesian State-Space Modeling of Age-Structured Data},
  abstract = {Explicit modeling of process variability in the dynamics of fisheries is motivated by a desire to incorporate more realism into stock assessment models, and much recent research effort has been devoted to the computational features of fitting state-space models for this purpose. Here, we extend the Bayesian application of nonlinear state-space modeling to sequential population analysis of age-structured data using a model formulation that allows for unreported catches and incidental fishing mortality. It is shown that, once a familiarity with the general-purpose Bayesian software BUGS is acquired, implementing a state-space model is a relatively simple task. Indeed, this application requires just 18 lines of code in its entirety and does not require the programmer to know the formulae for any prior density functions or likelihoods. Consequently, we suggest that this methodology may permit the implementation phase of nonlinear state-space modeling to be relegated, thereby allowing more effort to be devoted..., La mod{\'e}lisation explicite de la variabilit{\'e} des processus en dynamique des p{\^e}ches d{\'e}coule de l'intention de rendre plus r{\'e}alistes les mod{\`e}les d'{\'e}valuation des stocks, et beaucoup de recherches ont {\'e}t{\'e} consacr{\'e}es r{\'e}cemment aux caract{\'e}ristiques computationnelles de l'ajustement des mod{\`e}les {\'e}tat-espace. Dans le pr{\'e}sent cas, nous {\'e}tendons l'application bay{\'e}sienne de la mod{\'e}lisation non-lin{\'e}aire {\'e}tat-espace {\`a} l'analyse s{\'e}quentielle de population de donn{\'e}es structur{\'e}es par {\^a}ges en faisant appel {\`a} une formulation du mod{\`e}le qui permet de tenir compte des captures non signal{\'e}es et de la mortalit{\'e} par p{\^e}che accidentelle. Il est montr{\'e} que l'utilisation d'un mod{\`e}le {\'e}tat-espace s'av{\`e}re relativement simple une fois que l'on conna{\^i}t assez bien le logiciel bay{\'e}sien g{\'e}n{\'e}ral BUGS. Une telle application n'exige que 18 lignes de codes au total et le programmeur n'a pas {\`a} conna{\^i}tre les formules des fonctions de densit{\'e} ou de ressemblance ant{\'e}rieures. Nous croyons donc que cette m{\'e}thode pourrait permettre de d{\'e}laisser l'{\'e}tape...},
  number = {1},
  journal = {Can. J. Fish. Aquat. Sci.},
  doi = {10.1139/f99-169},
  author = {Millar, Russell B and Meyer, Renate},
  month = jan,
  year = {2000},
  pages = {43-50},
  file = {/home/jkbest/Dropbox/Zotero/storage/3EHQ6SSG/Millar and Meyer - 2000 - Bayesian state-space modeling of age-structured data.pdf}
}

@article{AbiaEtAl2005,
  series = {Special {{Issue}} on {{Theoretical Ecology}} and {{Mathematical Modelling}}: {{Problems}} and {{Methods}}},
  title = {Age-Structured Population Models and Their Numerical Solution},
  volume = {188},
  issn = {0304-3800},
  abstract = {This paper considers the state of the art of the numerical solution of age-structured population models. The different numerical approaches to this kind of problems and the stability and convergence results for them are reviewed. Both characteristic curves methods and finite difference methods are compared with regards to accuracy, efficiency and their qualitative behaviour depending on the compatibility conditions between initial and boundary data of the problems. The paper is the first of a series of two considering the numerical solution of general structured population models.},
  number = {1},
  journal = {Ecol. Model.},
  doi = {10.1016/j.ecolmodel.2005.05.007},
  author = {Abia, L. M. and Angulo, O. and {L{\'o}pez-Marcos}, J. C.},
  month = oct,
  year = {2005},
  keywords = {Age-structured population models,Characteristic curves methods,Finite difference methods,Gurtin–MacCamy equation,Initial and boundary data compatibility conditions},
  pages = {112-136},
  file = {/home/jkbest/Dropbox/Zotero/storage/CQCHJQ2V/Abia et al. - 2005 - Age-structured population models and their numerical solution.pdf}
}

@article{Tahvonen2008,
  title = {Harvesting an Age-Structured Population as Biomass: Does It Work?},
  volume = {21},
  copyright = {\textcopyright{}2008 Wiley Periodicals, Inc.},
  issn = {1939-7445},
  shorttitle = {Harvesting an {{Age}}-{{Structured Population}} as {{Biomass}}},
  abstract = {The economics of fisheries is based heavily on describing fish populations by the surplus production model. Both economists and ecologists have different opinions on whether this approach provides an adequate biological basis for economic analysis. This study takes an age-structured population model and shows how, under equilibrium conditions, it determines the surplus production model. The surplus production model is then used to solve an optimal feedback policy for a generic optimal harvesting problem. Next, it is assumed that the fishery manager applies this feedback policy even though the fish population actually evolves according to the age-structured model. This framework is applied to the widow rockfish, Atlantic menhaden, and Pacific halibut fisheries. Population age-structure contains information on future harvest possibilities. The surplus production model neglects this information and may lead to major deviations between the expected and actual outcomes especially under multiple steady states and nonlinearities.},
  language = {en},
  number = {4},
  journal = {Nat. Resour. Model.},
  doi = {10.1111/j.1939-7445.2008.00022.x},
  author = {Tahvonen, Olli},
  month = dec,
  year = {2008},
  keywords = {age-structured population models,fishery economics,Optimal harvesting,surplus production models},
  pages = {525-550},
  file = {/home/jkbest/Dropbox/Zotero/storage/4QRFHBU9/Tahvonen - 2008 - Harvesting an age-structured population as biomass.pdf}
}

@article{PellaTomlinson1969,
  title = {A Generalized Stock Production Model},
  volume = {13},
  abstract = {A generalization fo the Schaefer model is descibed which allows for skewness of the stock production curve relating production with population size. A fitting scheme is developed by which the stock production curve can be determined for an exploited fishery using only the catch and effort history of the fishery. Examplies are provided which demonstrate the suitability of the model for describing the dynamics of certain fish populations. In particular the catch and effort history for the yellowfin tuna fishery in the eastern Pacific Ocean is analyzed.},
  number = {3},
  journal = {Inter-Am. Trop. Tuna Comm. Bull.},
  author = {Pella, Jerome J. and Tomlinson, Patrick K.},
  year = {1969},
  keywords = {Surplus production model,⛔ No DOI found},
  pages = {421-458},
  file = {/home/jkbest/Dropbox/Zotero/storage/299NGKTT/Pella and Tomlinson - 1969 - A generalized stock production model.pdf}
}

@article{Fletcher1975,
  title = {A General Solution for the Complete {{Richards}} Function},
  volume = {27},
  issn = {0025-5564},
  abstract = {The two governing equations and corresponding solutions that constitute the complete Richards formulation are cast into a composite Bernoulli form, and the independent parameters are uncoupled. Examination of the governing equations in the first- and second-order phase planes leads to a simple relationship that permits a direct particular- ization of the Richards function on casual grounds. The analysis is accomodated by a canonical parametric system that accounts for the behavior of any inflecting-type growth law directly in terms of its analytical components. Certain use limitations of the Richards function are also clarified.},
  number = {3},
  journal = {Mathematical Biosciences},
  doi = {10.1016/0025-5564(75)90112-1},
  author = {Fletcher, R. Ian},
  month = jan,
  year = {1975},
  pages = {349-360},
  file = {/home/jkbest/Dropbox/Zotero/storage/ZTU2AB6T/Fletcher - 1975 - A general solution for the complete Richards function.pdf},
  ids = {Fletcher1975a}
}

@article{Fletcher1978,
  title = {Time-Dependent Solutions and Efficient Parameters for Stock-Production Models},
  volume = {76},
  abstract = {The time-dependent formulations of the Graham-Schaefer and Pella-Tomlinson systems are restructured so as to accommodate directly the critical-point parameters of their respective governing graphs; the resulting parametric system accounts for the behavior ofeither model wholly in terms ofits management components. The indeterminate exponent and the coefficients of the Pella-Tomlinson equations are uncoupled and the dual formulations associated with the conventional casting of the system are eliminated; the governing equations and corresponding solutions are cast into composite forms and the sign changes of coefficients become automatic. The previously obscure relationships between management parameters and variable graph curvature in the Pella-Tomlinson model are expressly formulated; maximum sustainable yield is shown to be independent of the indeterminacy of the system. Time-delay estimators for both systems are formulated.},
  language = {en},
  number = {2},
  journal = {Fish. Bull.},
  author = {Fletcher, R. Ian},
  year = {1978},
  keywords = {⛔ No DOI found},
  pages = {377-388},
  file = {/home/jkbest/Dropbox/Zotero/storage/UYB2SAGX/Fletcher - 1978 - Time-dependent solutions and efficient parameters for stock-production models.pdf}
}

@article{Wood2010,
  title = {Statistical Inference for Noisy Nonlinear Ecological Dynamic Systems},
  volume = {466},
  copyright = {2010 Nature Publishing Group},
  issn = {1476-4687},
  abstract = {Chaotic ecological dynamic systems defy conventional statistical analysis. Systems with near-chaotic dynamics are little better. Such systems are almost invariably driven by endogenous dynamic processes plus demographic and environmental process noise, and are only observable with error. Their sensitivity to history means that minute changes in the driving noise realization, or the system parameters, will cause drastic changes in the system trajectory1. This sensitivity is inherited and amplified by the joint probability density of the observable data and the process noise, rendering it useless as the basis for obtaining measures of statistical fit. Because the joint density is the basis for the fit measures used by all conventional statistical methods2, this is a major theoretical shortcoming. The inability to make well-founded statistical inferences about biological dynamic models in the chaotic and near-chaotic regimes, other than on an ad hoc basis, leaves dynamic theory without the methods of quantitative validation that are essential tools in the rest of biological science. Here I show that this impasse can be resolved in a simple and general manner, using a method that requires only the ability to simulate the observed data on a system from the dynamic model about which inferences are required. The raw data series are reduced to phase-insensitive summary statistics, quantifying local dynamic structure and the distribution of observations. Simulation is used to obtain the mean and the covariance matrix of the statistics, given model parameters, allowing the construction of a `synthetic likelihood' that assesses model fit. This likelihood can be explored using a straightforward Markov chain Monte Carlo sampler, but one further post-processing step returns pure likelihood-based inference. I apply the method to establish the dynamic nature of the fluctuations in Nicholson's classic blowfly experiments3,4,5.},
  language = {en},
  number = {7310},
  journal = {Nature},
  doi = {10.1038/nature09319},
  author = {Wood, Simon N.},
  month = aug,
  year = {2010},
  pages = {1102-1104},
  file = {/home/jkbest/Dropbox/Zotero/storage/4S2PTAUV/Wood - 2010 - Statistical inference for noisy nonlinear ecological dynamic systems.pdf}
}

@article{Geyer1992,
  title = {Practical {{Markov}} Chain {{Monte Carlo}}},
  volume = {7},
  issn = {0883-4237},
  abstract = {Markov chain Monte Carlo using the Metropolis-Hastings algorithm is a general method for the simulation of stochastic processes having probability densities known up to a constant of proportionality. Despite recent advances in its theory, the practice has remained controversial. This article makes the case for basing all inference on one long run of the Markov chain and estimating the Monte Carlo error by standard nonparametric methods well-known in the time-series and operations research literature. In passing it touches on the Kipnis-Varadhan central limit theorem for reversible Markov chains, on some new variance estimators, on judging the relative efficiency of competing Monte Carlo schemes, on methods for constructing more rapidly mixing Markov chains and on diagnostics for Markov chain Monte Carlo.},
  number = {4},
  journal = {Stat. Sci.},
  author = {Geyer, Charles J.},
  year = {1992},
  keywords = {❓ Multiple DOI},
  pages = {473-483},
  file = {/home/jkbest/Dropbox/Zotero/storage/GHDMGPM4/Geyer - 1992 - Practical Markov chain Monte Carlo.pdf}
}

@article{PolacheckEtAl1993,
  title = {Fitting Surplus Production Models: Comparing Methods and Measuring Uncertainty},
  volume = {50},
  issn = {0706-652X},
  shorttitle = {Fitting {{Surplus Production Models}}},
  abstract = {Three approaches are commonly used to fit surplus production models to observed data: effort-averaging methods; process-error estimators; and observation-error estimators. We compare these approaches using real and simulated data sets, and conclude that they yield substantially different interpretations of productivity. Effort-averaging methods assume the stock is in equilibrium relative to the recent effort; this assumption is rarely satisfied and usually leads to overestimation of potential yield and optimum effort. Effort-averaging methods will almost always produce what appears to be "reasonable" estimates of maximum sustainable yield and optimum effort, and the r2 statistic used to evaluate the goodness of fit can provide an unrealistic illusion of confidence about the parameter estimates obtained. Process-error estimators produce much less reliable estimates than observation-error estimators. The observation-error estimator provides the lowest estimates of maximum sustainable yield and optimum effor..., On emploie commun{\'e}ment trois m{\'e}thodes pour ajuster les mod{\`e}les de production exc{\'e}dentaire aux r{\'e}sultats observ{\'e}s; il y a les m{\'e}thodes de la moyenne d'effort, les estimateurs des erreurs de traitement ainsi que les estimateurs des erreurs d'observation. Nous comparons ces trois d{\'e}marches au moyen d'ensembles de donn{\'e}es r{\'e}elles et simul{\'e}es, et nous parvenons {\`a} la conclusion que ces m{\'e}thodes conduisent {\`a} des interpr{\'e}tations largement diff{\'e}rentes de la productivit{\'e}. Les m{\'e}thodes fond{\'e}es sur les moyennes d'effort supposent que le stock est en {\'e}quilibre relativement {\`a} l'effort r{\'e}cent; c'est rarement le cas, mais cela conduit ordinairement {\`a} une surestimation du rendement potentiel et de l'effort optimal. Ces m{\'e}thodes produiront presque toujours ce qui semble {\^e}tre des estimations \guillemotleft{} raisonnables \guillemotright{} du rendement soutenable maximal et de l'effort optimal, et la valeur statistique r2 qui sert {\`a} {\'e}valuer la validit{\'e} de l'ajustement peut donner l'illusion non fond{\'e}e de confiance dans les estimations des param{\`e}tres qui s...},
  number = {12},
  journal = {Can. J. Fish. Aquat. Sci.},
  doi = {10.1139/f93-284},
  author = {Polacheck, Tom and Hilborn, Ray and Punt, Andre E.},
  month = dec,
  year = {1993},
  pages = {2597-2607},
  file = {/home/jkbest/Dropbox/Zotero/storage/BHE7W6ZK/Polacheck et al. - 1993 - Fitting surplus production models.pdf}
}

@article{ColvinEtAl2012,
  title = {Semidiscrete Biomass Dynamic Modeling: An~Improved Approach for Assessing Fish Stock Responses to Pulsed Harvest Events},
  volume = {69},
  issn = {0706-652X},
  shorttitle = {Semidiscrete Biomass Dynamic Modeling},
  abstract = {Continuous harvest over an annual period is a common assumption of continuous biomass dynamics models (CBDMs); however, fish are frequently harvested in a discrete manner. We developed semidiscrete biomass dynamics models (SDBDMs) that allow discrete harvest events and evaluated differences between CBDMs and SDBDMs using an equilibrium yield analysis with varying levels of fishing mortality~(F). Equilibrium fishery yields for CBDMs and SDBDMS were similar at low fishing mortalities and diverged as F approached and exceeded maximum sustained yield (FMSY). Discrete harvest resulted in lower equilibrium yields at high levels of F relative to continuous harvest. The effect of applying harvest continuously when it was in fact discrete was evaluated by fitting CBDMs and SDBDMs to time series data generated from a hypothetical fish stock undergoing discrete harvest and evaluating parameter estimates bias. Violating the assumption of continuous harvest resulted in biased parameter estimates for CBDM while SDBDM p..., Si les mod{\`e}les continus de dynamique de la biomasse (CBDM) partent souvent du principe que la capture est continue au cours d'une p{\'e}riode annuelle, les prises de poissons s'effectuent fr{\'e}quemment de mani{\`e}re discr{\`e}te. Nous avons mis au point des mod{\`e}les semidiscrets de dynamique de la biomasse (SDBDM) qui permettent l'int{\'e}gration d'{\'e}v{\`e}nements de prise discrets et avons {\'e}valu{\'e} les diff{\'e}rences entre les CBDM et les SDBDM {\`a} la lumi{\`e}re d'une analyse du rendement {\'e}quilibr{\'e} {\`a} diff{\'e}rents taux de mortalit{\'e} par p{\^e}che (F). {\`A} de faibles F, les CBDM et les SDBDM ont donn{\'e} des rendements {\'e}quilibr{\'e}s semblables, l'{\'e}cart entre ces derniers augmentant {\`a} mesure que F s'approche puis d{\'e}passe le rendement maximum durable (FMSY). L'int{\'e}gration de prises discr{\`e}tes s'est traduite par des rendements {\'e}quilibr{\'e}s plus faibles {\`a} des F {\'e}lev{\'e}s que ceux obtenus pour des prises continues. L'incidence de l'utilisation de prises continues dans des cas o{\`u} les prises sont en fait discr{\`e}tes a {\'e}t{\'e} {\'e}valu{\'e}e en ajustant les CBDM et les SDBDM aux ...},
  number = {10},
  journal = {Can. J. Fish. Aquat. Sci.},
  doi = {10.1139/f2012-084},
  author = {Colvin, Michael E. and Pierce, Clay L. and Stewart, Timothy W.},
  month = sep,
  year = {2012},
  pages = {1710-1721},
  file = {/home/jkbest/Dropbox/Zotero/storage/Z4BPZEHC/Colvin et al. - 2012 - Semidiscrete biomass dynamic modeling.pdf}
}

@article{Kalman1960,
  title = {A New Approach to Linear Filtering and Prediction Problems},
  volume = {82},
  issn = {0098-2202},
  abstract = {The classical filtering and prediction problem is re-examined using the Bode-Shannon representation of random processes and the ``state-transition'' method of analysis of dynamic systems. New results are: (1) The formulation and methods of solution of the problem apply without modification to stationary and nonstationary statistics and to growing-memory and infinite-memory filters. (2) A nonlinear difference (or differential) equation is derived for the covariance matrix of the optimal estimation error. From the solution of this equation the co-efficients of the difference (or differential) equation of the optimal linear filter are obtained without further calculations. (3) The filtering problem is shown to be the dual of the noise-free regulator problem. The new method developed here is applied to two well-known problems, confirming and extending earlier results. The discussion is largely self-contained and proceeds from first principles; basic concepts of the theory of random processes are reviewed in the Appendix.},
  number = {1},
  journal = {J. Basic Eng.},
  doi = {10.1115/1.3662552},
  author = {Kalman, R. E.},
  month = mar,
  year = {1960},
  pages = {35-45},
  file = {/home/jkbest/Dropbox/Zotero/storage/TLVVHKH6/Kalman - 1960 - A new approach to linear filtering and prediction problems.pdf}
}

@incollection{Neal2011,
  address = {{Boca Raton}},
  series = {Handbooks of {{Modern Statistical Methods}}},
  title = {{{MCMC}} Using {{Hamiltonian}} Dynamics},
  isbn = {978-1-4200-7942-5},
  abstract = {Markov chain Monte Carlo (MCMC) originated with the classic paper of Metropolis et al. (1953), where it was used to simulate the distribution of states for a system of idealized molecules. Not long after, another approach to molecular simulation was introduced (Alder and Wainwright, 1959), in which the motion of the molecules was deterministic, following Newton's laws of motion, which have an elegant formalization as Hamiltonian dynamics. For finding the properties of bulk materials, these approaches are asymptotically equivalent, since even in a deterministic simulation, each local region of the material experiences effectively random influences from distant regions. Despite the large overlap in their application areas, the MCMC and molecular dynamics approaches have continued to coexist in the following decades (see Frenkel and Smit, 1996).},
  language = {English},
  booktitle = {Handbook of {{Markov}} Chain {{Monte Carlo}}},
  publisher = {{Taylor \& Francis}},
  author = {Neal, Radford M.},
  editor = {Brooks, Steve and Gelman, Andrew and Jones, Galin L. and Meng, Xiao-Li},
  year = {2011},
  pages = {113-162},
  note = {OCLC: 753969788}
}

@article{GilksEtAl1994,
  title = {A Language and Program for Complex {{Bayesian}} Modelling},
  volume = {43},
  issn = {0039-0526},
  abstract = {Gibbs sampling has enormous potential for analysing complex data sets. However, routine use of Gibbs sampling has been hampered by the lack of general purpose software for its implementation. Until now all applications have involved writing one-off computer code in low or intermediate level languages such as C or Fortran. We describe some general purpose software that we are currently developing for implementing Gibbs sampling: BUGS (Bayesian inference using Gibbs sampling). The BUGS system comprises three components: first, a natural language for specifying complex models; second, an 'expert system' for deciding appropriate methods for obtaining samples required by the Gibbs sampler: third, a sampling module containing numerical routines to perform the sampling. \$S\$ objects are used for data input and output. BUGS is written in Modula-2 and runs under both DOS and UNIX.},
  number = {1},
  journal = {J. Royal Stat. Soc. D},
  doi = {10.2307/2348941},
  author = {Gilks, W. R. and Thomas, A. and Spiegelhalter, D. J.},
  year = {1994},
  pages = {169-177},
  file = {/home/jkbest/Dropbox/Zotero/storage/5HWW4AU6/Gilks et al. - 1994 - A language and program for complex Bayesian modelling.pdf}
}

@article{Kitagawa1996,
  title = {Monte {{Carlo}} Filter and Smoother for Non-{{Gaussian}} Nonlinear State Space Models},
  volume = {5},
  issn = {1061-8600},
  abstract = {[A new algorithm for the prediction, filtering, and smoothing of non-Gaussian nonlinear state space models is shown. The algorithm is based on a Monte Carlo method in which successive prediction, filtering (and subsequently smoothing), conditional probability density functions are approximated by many of their realizations. The particular contribution of this algorithm is that it can be applied to a broad class of nonlinear non-Gaussian higher dimensional state space models on the provision that the dimensions of the system noise and the observation noise are relatively low. Several numerical examples are shown.]},
  number = {1},
  journal = {J. Comput. Graph. Stat.},
  doi = {10.2307/1390750},
  author = {Kitagawa, Genshiro},
  year = {1996},
  pages = {1-25},
  file = {/home/jkbest/Dropbox/Zotero/storage/YWZY9PIZ/Kitagawa - 1996 - Monte Carlo filter and smoother for non-Gaussian nonlinear state space models.pdf}
}

@article{CarlinEtAl1992,
  title = {A {{Monte Carlo}} Approach to Nonnormal and Nonlinear State-Space Modeling},
  volume = {87},
  issn = {0162-1459},
  abstract = {[A solution to multivariate state-space modeling, forecasting, and smoothing is discussed. We allow for the possibilities of nonnormal errors and nonlinear functionals in the state equation, the observational equation, or both. An adaptive Monte Carlo integration technique known as the Gibbs sampler is proposed as a mechanism for implementing a conceptually and computationally simple solution in such a framework. The methodology is a general strategy for obtaining marginal posterior densities of coefficients in the model or of any of the unknown elements of the state space. Missing data problems (including the k-step ahead prediction problem) also are easily incorporated into this framework. We illustrate the broad applicability of our approach with two examples: a problem involving nonnormal error distributions in a linear model setting and a one-step ahead prediction problem in a situation where both the state and observational equations are nonlinear and involve unknown parameters.]},
  number = {418},
  journal = {J. Am. Stat. Assoc.},
  doi = {10.2307/2290282},
  author = {Carlin, Bradley P. and Polson, Nicholas G. and Stoffer, David S.},
  year = {1992},
  pages = {493-500},
  file = {/home/jkbest/Dropbox/Zotero/storage/JZ5D6F7Y/Carlin et al - 1992 - A Monte Carlo Approach to Nonnormal and Nonlinear State-Space Modeling.pdf}
}

@inproceedings{Plummer2003,
  address = {{Vienna, Austria}},
  title = {{{JAGS}}: {{A}} Program for Analysis of {{Bayesian}} Graphical Models Using {{Gibbs}} Sampling},
  abstract = {JAGS is a program for Bayesian Graphical modelling which aims for compatibility with Classic BUGS. The program could eventually be developed as an R package. This article explains the motivations for this program, briefly describes the architecture and then discusses some ideas for a vectorized form of the BUGS language.},
  language = {en},
  booktitle = {Proceedings of the 3rd {{International Workshop}} on {{Distributed Statistical Computing}}},
  author = {Plummer, Martyn},
  year = {2003},
  keywords = {⛔ No DOI found},
  file = {/home/jkbest/Dropbox/Zotero/storage/LXJ2U93D/Plummer - 2003 - JAGS.pdf}
}

@article{HoffmanGelman2014,
  title = {The {{No}}-{{U}}-{{Turn Sampler}}: Adaptively Setting Path Lengths in {{Hamiltonian Monte Carlo}}},
  volume = {15},
  abstract = {Hamiltonian Monte Carlo (HMC) is a Markov chain Monte Carlo (MCMC) algorithm that avoids the random walk behavior and sensitivity to correlated parameters that plague many MCMC methods by taking a series of steps informed by first-order gradient information. These features allow it to converge to high-dimensional target distributions much more quickly than simpler methods such as random walk Metropolis or Gibbs sampling. However, HMC's performance is highly sensitive to two user-specified parameters: a step size and a desired number of steps L. In particular, if L is too small then the algorithm exhibits undesirable random walk behavior, while if L is too large the algorithm wastes computation. We introduce the No-U-Turn Sampler (NUTS), an extension to HMC that eliminates the need to set a number of steps L. NUTS uses a recursive algorithm to build a set of likely candidate points that spans a wide swath of the target distribution, stopping automatically when it starts to double back and retrace its steps. Empirically, NUTS performs at least as efficiently as (and sometimes more efficiently than) a well tuned standard HMC method, without requiring user intervention or costly tuning runs. We also derive a method for adapting the step size parameter on the fly based on primal-dual averaging. NUTS can thus be used with no hand-tuning at all, making it suitable for applications such as BUGS-style automatic inference engines that require efficient ``turnkey'' samplers.},
  language = {en},
  journal = {J. Mach. Learn. Res.},
  author = {Hoffman, Matthew D and Gelman, Andrew},
  month = apr,
  year = {2014},
  keywords = {⛔ No DOI found},
  pages = {1593-1623},
  file = {/home/jkbest/Dropbox/Zotero/storage/3SMKRPZP/Hoffman and Gelman - 2014 - The No-U-Turn Sampler.pdf}
}

@article{VatsKnudson2018,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1812.09384},
  primaryClass = {stat},
  title = {Revisiting the {{Gelman}}-{{Rubin Diagnostic}}},
  abstract = {Gelman and Rubin's (1992) convergence diagnostic is one of the most popular methods for terminating a Markov chain Monte Carlo (MCMC) sampler. Since the seminal paper, researchers have developed sophisticated methods of variance estimation for Monte Carlo averages. We show that this class of estimators find immediate use in the Gelman-Rubin statistic, a connection not established in the literature before. We incorporate these estimators to upgrade both the univariate and multivariate Gelman-Rubin statistics, leading to increased stability in MCMC termination time. An immediate advantage is that our new Gelman-Rubin statistic can be calculated for a single chain. In addition, we establish a relationship between the Gelman-Rubin statistic and effective sample size. Leveraging this relationship, we develop a principled cutoff criterion for the Gelman-Rubin statistic. Finally, we demonstrate the utility of our improved diagnostic via examples.},
  journal = {arXiv},
  author = {Vats, Dootika and Knudson, Christina},
  month = dec,
  year = {2018},
  keywords = {Statistics - Methodology,Statistics - Computation,⛔ No DOI found},
  file = {/home/jkbest/Dropbox/Zotero/storage/8KAU6KPX/Vats and Knudson - 2018 - Revisiting the Gelman-Rubin Diagnostic.pdf}
}

@misc{RCoreTeam2019,
  address = {{Vienna, Austria}},
  title = {R: A Language and Environment for Statistical Computing},
  howpublished = {R Foundation for Statistical Computing},
  author = {{R Core Team}},
  year = {2019}
}

@article{GrussEtAl2019,
  title = {Evaluation of the Impacts of Different Treatments of Spatio-Temporal Variation in Catch-per-Unit-Effort Standardization Models},
  volume = {213},
  issn = {0165-7836},
  abstract = {Many stock assessments heavily rely on indices of relative abundance derived from fisheries-dependent catch-per-unit-effort (CPUE) data. Therefore, it is critical to evaluate different CPUE standardization methods under varying scenarios of data generating processes. Here, we evaluated nine CPUE standardization methods offering contrasting treatments of spatio-temporal variation, ranging from the basic generalized linear model (GLM) method not integrating a year-area interaction term to a sophisticated method using the spatio-temporal modeling platform VAST. We compared the performance of these methods against simulated data constructed to mimic the processes generating fisheries-dependent information for Atlantic blue marlin (Makaira nigricans), a common bycatch population in pelagic longline fisheries. Data were generated using a longline data simulator for different population trajectories (increasing, decreasing, and static). These data were further subsampled to mimic an observer program where trips rather than sets form the sampling frame, with or without a bias towards trips with low catch rates, which might occur if the presence of an observer alters fishing behavior to avoid bycatch. The spatio-temporal modeling platform VAST achieved the best performance in simulation, namely generally had one of the lowest biases, one of the lowest mean absolute errors (MAEs), and 50\% confidence interval coverage closest to 50\%. Generalized additive models accounting for spatial autocorrelation at a broad spatial scale (one of the lowest MAEs and one of the lowest biases) and, to a lesser extent, non-spatial delta-lognormal GLMs including a year-area interaction as a random effect (one of the lowest MAEs and one of the best confidence interval coverages) also performed adequately. The VAST method provided the most comprehensive and consistent treatment of spatio-temporal variation, in contrast with methods that simply weight predictions by large spatial areas, where it is critical, but difficult, to get the a priori spatial stratification correct before weighting. Next, we applied the CPUE standardization methods to real data collected by the National Marine Fisheries Service Pelagic Observer Program. The indices of relative abundance predicted from real observer data were relatively similar across CPUE standardization methods for the period 1998\textendash{}2017 and suggested that the blue marlin population of the Atlantic declined over the period 1998\textendash{}2004 and was relatively stable afterwards. As spatio-temporal variation related to environmental changes or depletion becomes increasingly necessary to consider, greater use of spatio-temporal models for standardizing fisheries-dependent CPUE data will likely be warranted.},
  journal = {Fish. Res.},
  doi = {10.1016/j.fishres.2019.01.008},
  author = {Gr{\"u}ss, Arnaud and Walter, John F. and Babcock, Elizabeth A. and Forrestal, Francesca C. and Thorson, James T. and Lauretta, Matthew V. and Schirripa, Michael J.},
  month = may,
  year = {2019},
  keywords = {Catch-per-unit-effort (CPUE),Indices of relative abundance,Simulation-testing,Spatio-temporal models,Standardization methods,VAST,fishery-dependent},
  pages = {75-93},
  file = {/home/jkbest/Dropbox/Zotero/storage/E4ZQAW2Z/Grüss et al. - 2019 - Evaluation of the impacts of different treatments of spatio-temporal variation.pdf},
  note = {Citation Key Alias: Gruss2019, Gruss2019a}
}

@article{Millar2002,
  title = {Reference Priors for {{Bayesian}} Fisheries Models},
  volume = {59},
  issn = {0706-652X},
  abstract = {Bayesian models require the specification of prior distributions for all unknown parameters, and this formal utilization of prior knowledge (if any) can be used to great advantage in some fisheries. However, regardless of whether prior knowledge about model parameters is available, specification of prior distributions is seldom unequivocal. This work addresses the problem of specifying default priors for several common fisheries models. To maintain consistency of terminology with the statistical literature, such priors are herein called reference priors to recognize that they can be interpreted as providing a sensible reference point against which the implications of alternative priors can be compared. Here, the Jeffreys' prior is demonstrated for the Ricker and BevertonHolt stockrecruit curves, von Bertalanffy growth curve, Schaefer surplus production model, and sequential population analysis. The Jeffreys' priors for relevant derived parameters are demonstrated, including the steepness parameter of th..., Les mod{\`e}les bay{\'e}siens exigent que l'on sp{\'e}cifie des distributions a priori pour tous les param{\`e}tres inconnus et cette utilisation formelle de donn{\'e}es a priori (lorsqu'elles existent) est d'une grande utilit{\'e} dans l'{\'e}tude de certaines p{\^e}ches commerciales. Cependant, qu'il y ait ou non des informations a priori sur les param{\`e}tres du mod{\`e}le, l'attribution des distributions a priori est rarement sans {\'e}quivoque. On trouvera ici un examen du probl{\`e}me d'assigner des distributions a priori dans plusieurs mod{\`e}les courants utilis{\'e}s en halieutique. Pour maintenir une uniformit{\'e} de terminologie avec la litt{\'e}rature statistique, ces distributions {\`a} priori sont appel{\'e}es distributions a priori de r{\'e}f{\'e}rence pour indiquer qu'elles peuvent procurer un point de r{\'e}f{\'e}rence cr{\'e}dible auquel les caract{\'e}ristiques d'autres distributions a priori de rechange peuvent {\^e}tre compar{\'e}es. La distribution a priori de Jeffreys est d{\'e}termin{\'e}e pour les courbes de stockrecrutement de Ricker et de BevertonHolt, la courbe de croissance de von B...},
  number = {9},
  journal = {Can. J. Fish. Aquat. Sci.},
  doi = {10.1139/f02-108},
  author = {Millar, Russell B},
  month = sep,
  year = {2002},
  pages = {1492-1502},
  file = {/home/jkbest/Dropbox/Zotero/storage/CYLWT5BL/Millar - 2002 - Reference priors for Bayesian fisheries models.pdf}
}

@article{ThorsonEtAl2014a,
  title = {A {{Bayesian}} Approach to Identifying and Compensating for Model Misspecification in Population Models},
  volume = {95},
  copyright = {\textcopyright{} 2014 by the Ecological Society of America},
  issn = {1939-9170},
  abstract = {State-space estimation methods are increasingly used in ecology to estimate productivity and abundance of natural populations while accounting for variability in both population dynamics and measurement processes. However, functional forms for population dynamics and density dependence often will not match the true biological process, and this may degrade the performance of state-space methods. We therefore developed a Bayesian semiparametric state-space model, which uses a Gaussian process (GP) to approximate the population growth function. This offers two benefits for population modeling. First, it allows data to update a specified ``prior'' on the population growth function, while reverting to this prior when data are uninformative. Second, it allows variability in population dynamics to be decomposed into random errors around the population growth function (``process error'') and errors due to the mismatch between the specified prior and estimated growth function (``model error''). We used simulation modeling to illustrate the utility of GP methods in state-space population dynamics models. Results confirmed that the GP model performs similarly to a conventional state-space model when either (1) the prior matches the true process or (2) data are relatively uninformative. However, GP methods improve estimates of the population growth function when the function is misspecified. Results also demonstrated that the estimated magnitude of ``model error'' can be used to distinguish cases of model misspecification. We conclude with a discussion of the prospects for GP methods in other state-space models, including age and length-structured, meta-analytic, and individual-movement models.},
  language = {en},
  number = {2},
  journal = {Ecol.},
  doi = {10.1890/13-0187.1},
  author = {Thorson, James T. and Ono, Kotaro and Munch, Stephan B.},
  year = {2014},
  keywords = {Gaussian process,state-space models,Bayesian models,model misspecification,population dynamics model,semiparametric models},
  pages = {329-341},
  file = {/home/jkbest/Dropbox/Zotero/storage/K3PFTEF6/Thorson et al. - 2014 - A Bayesian approach to identifying and compensating for model misspecification.pdf}
}

@article{ZhouEtAl2010,
  title = {Modified Hierarchical {{Bayesian}} Biomass Dynamics Models for Assessment of Short-Lived Invertebrates: A Comparison for Tropical Tiger Prawns},
  volume = {60},
  issn = {1448-6059},
  shorttitle = {Modified Hierarchical {{Bayesian}} Biomass Dynamics Models for Assessment of Short-Lived Invertebrates},
  abstract = {Conventional biomass dynamics models express next year's biomass as this year's biomass plus surplus production less catch. These models are typically applied to species with several age-classes but it is unclear how well they perform for short-lived species with low survival and high recruitment variation. Two alternative versions of the standard biomass dynamics model (Standard) were constructed for short-lived species by ignoring the `old biomass' term (Annual), and assuming that the biomass at the start of the next year depends on density-dependent processes that are a function of that biomass (Stock-recruit). These models were fitted to catch and effort data for the grooved tiger prawn Penaeus semisulcatus using a hierarchical Bayesian technique. The results from the biomass dynamics models were compared with those from more complicated weekly delay-difference models. The analyses show that: the Standard model is flexible for short-lived species; the Stock-recruit model provides the most parsimonious fit; simple biomass dynamics models can provide virtually identical results to data-demanding models; and spatial variability in key population dynamics parameters exists for P. semisulacatus. The method outlined in this paper provides a means to conduct quantitative population assessments for data-limited short-lived species.},
  language = {en},
  number = {12},
  journal = {Mar. Freshw. Res.},
  doi = {10.1071/MF09022},
  author = {Zhou, Shijie and Punt, Andr{\'e} E. and Deng, Roy and Dichmont, Catherine M. and Ye, Yimin and Bishop, Janet},
  month = jan,
  year = {2010},
  pages = {1298-1308},
  file = {/home/jkbest/Dropbox/Zotero/storage/YTP6FHKA/Zhou et al. - 2010 - Modified hierarchical Bayesian biomass dynamics models for assessment of.pdf}
}

@article{JiaoEtAl2011,
  title = {Poor-Data and Data-Poor Species Stock Assessment Using a {{Bayesian}} Hierarchical Approach},
  volume = {21},
  copyright = {\textcopyright{} 2011 by the Ecological Society of America},
  issn = {1939-5582},
  abstract = {Appropriate inference for stocks or species with low-quality data (poor data) or limited data (data poor) is extremely important. Hierarchical Bayesian methods are especially applicable to small-area, small-sample-size estimation problems because they allow poor-data species to borrow strength from species with good-quality data. We used a hammerhead shark complex as an example to investigate the advantages of using hierarchical Bayesian models in assessing the status of poor-data and data-poor exploited species. The hammerhead shark complex (Sphyrna spp.) along the Atlantic and Gulf of Mexico coasts of the United States is composed of three species: the scalloped hammerhead (S. lewini), the great hammerhead (S. mokarran), and the smooth hammerhead (S. zygaena) sharks. The scalloped hammerhead comprises 70\textendash{}80\% of the catch and has catch and relative abundance data of good quality, whereas great and smooth hammerheads have relative abundance indices that are both limited and of low quality presumably because of low stock density and limited sampling. Four hierarchical Bayesian state-space surplus production models were developed to simulate variability in population growth rates, carrying capacity, and catchability of the species. The results from the hierarchical Bayesian models were considerably more robust than those of the nonhierarchical models. The hierarchical Bayesian approach represents an intermediate strategy between traditional models that assume different population parameters for each species and those that assume all species share identical parameters. Use of the hierarchical Bayesian approach is suggested for future hammerhead shark stock assessments and for modeling fish complexes with species-specific data, because the poor-data species can borrow strength from the species with good data, making the estimation more stable and robust.},
  language = {en},
  number = {7},
  journal = {Ecol. Appl.},
  doi = {10.1890/10-0526.1},
  author = {Jiao, Yan and Cort{\'e}s, Enric and Andrews, Kate and Guo, Feng},
  year = {2011},
  keywords = {population dynamics,Bayesian hierarchical model,data-poor assessment,fish complex,hammerhead shark,small sample size},
  pages = {2691-2708},
  file = {/home/jkbest/Dropbox/Zotero/storage/9QSCNTVF/Jiao et al. - 2011 - Poor-data and data-poor species stock assessment using a Bayesian hierarchical.pdf}
}

@article{PedersenEtAl2011,
  title = {Estimation Methods for Nonlinear State-Space Models in Ecology},
  volume = {222},
  issn = {0304-3800},
  abstract = {The use of nonlinear state-space models for analyzing ecological systems is increasing. A wide range of estimation methods for such models are available to ecologists, however it is not always clear, which is the appropriate method to choose. To this end, three approaches to estimation in the theta logistic model for population dynamics were benchmarked by Wang (2007). Similarly, we examine and compare the estimation performance of three alternative methods using simulated data. The first approach is to partition the state-space into a finite number of states and formulate the problem as a hidden Markov model (HMM). The second method uses the mixed effects modeling and fast numerical integration framework of the AD Model Builder (ADMB) open-source software. The third alternative is to use the popular Bayesian framework of BUGS. The study showed that state and parameter estimation performance for all three methods was largely identical, however with BUGS providing overall wider credible intervals for parameters than HMM and ADMB confidence intervals.},
  number = {8},
  journal = {Ecol. Model.},
  doi = {10.1016/j.ecolmodel.2011.01.007},
  author = {Pedersen, M. W. and Berg, C. W. and Thygesen, U. H. and Nielsen, A. and Madsen, H.},
  month = apr,
  year = {2011},
  keywords = {AD Model Builder,WinBUGS,Hidden Markov model,Mixed model,Monte Carlo,Theta logistic population model},
  pages = {1394-1400},
  file = {/home/jkbest/Dropbox/Zotero/storage/DEU9SIKD/Pedersen et al. - 2011 - Estimation methods for nonlinear state-space models in ecology.pdf}
}

@article{DichmontEtAl2016,
  title = {A Review of Stock Assessment Packages in the {{United States}}},
  volume = {183},
  issn = {0165-7836},
  abstract = {Stock assessments provide scientific advice in support of fisheries decision making. Ideally, assessments involve fitting population dynamics models to fishery and monitoring data to provide estimates of time-trajectories of biomass and fishing mortality in absolute terms and relative to biological reference points such as BMSY and FMSY, along with measures of uncertainty. Some stock assessments are conducted using software developed for a specific stock or group of stocks. However, increasingly, stock assessments are being conducted using packages developed for application to several taxa and across multiple regions. We review the range of packages used to conduct assessments of fish and invertebrate stocks in the United States because these assessments tend to have common goals, and need to provide similar outputs for decision making. Sixteen packages are considered, five based on surplus production models, one based on a delay-difference model, and the remainder based on age-structured models. Most of the packages are freely available for use by analysts in the US and around the world, have been evaluated using simulations, and can form the basis for forecasts. The packages differ in their ease of use and the types of data inputs they can use. This paper highlights the benefits of stock assessment packages in terms of allowing analysts to explore many assessment configurations and facilitating the peer-review of assessments. It also highlights the disadvantages associated with the use of packages for conducting assessments. Packages with the most options and greatest flexibility are the most difficult to use, and see the greatest development of auxiliary tools to facilitate their use.},
  journal = {Fish. Res.},
  doi = {10.1016/j.fishres.2016.07.001},
  author = {Dichmont, Catherine M. and Deng, Roy A. and Punt, Andre E. and Brodziak, Jon and Chang, Yi-Jay and Cope, Jason M. and Ianelli, James N. and Legault, Christopher M. and Methot, Richard D. and Porch, Clay E. and Prager, Michael H. and Shertzer, Kyle W.},
  month = nov,
  year = {2016},
  keywords = {Stock assessment,Fishing mortality,Population dynamics,Reference points},
  pages = {447-460},
  file = {/home/jkbest/Dropbox/Zotero/storage/LKRCPAXG/Dichmont et al. - 2016 - A review of stock assessment packages in the United States.pdf}
}

@article{ICCAT2016,
  title = {Report of the 2015 {{ICCAT}} Blue Shark Stock Assessment Session},
  volume = {72},
  abstract = {The meeting was held at the Ocean{\'a}rio de Lisboa, Portugal, 27-31 July. The objective of this
meeting was to assess the status of the stocks (North and South) of Atlantic blue shark. The last
assessment was conducted in 2008 and targeting of longline fisheries has developed in recent
years.},
  language = {en},
  number = {4},
  journal = {Collect. Vol. Sci. Pap. ICCAT},
  author = {ICCAT},
  year = {2016},
  keywords = {⛔ No DOI found},
  pages = {866-1019},
  file = {/home/jkbest/Dropbox/Zotero/storage/DB9DQ799/ICCAT - 2016 - Report of the 2015 ICCAT blue shark stock assessment session.pdf}
}

@article{ISC2017,
  title = {Stock Assessment and Future Projections of Blue Shark in the {{North Pacific Ocean}} through 2015},
  journal = {International Scientific Committee for tuna and tuna-like species in the North Pacific Ocean},
  author = {ISC},
  month = jul,
  year = {2017},
  keywords = {⛔ No DOI found},
  pages = {96},
  file = {/home/jkbest/Dropbox/Zotero/storage/XWP58Z6J/ISC - 2017 - Stock assessment and future projections of blue shark in the North Pacific.pdf}
}

@article{ICCAT2017b,
  title = {Report of the 2017 {{ICCAT}} Shortfin Mako Stock Assessment Meeting},
  volume = {74},
  abstract = {The meeting was held in Madrid Spain, 12-16 June. The objective of this meeting was to assess
the status of the stocks (North and South) of Atlantic shortfin mako shark. The last assessment
was conducted in 2012. The populations were assessed using several models, from different types
of surplus production models to fully integrated age-structured models. For the first time,
projections of stock status were conducted for this species and management advice was provided
based on Kobe strategy matrices. The assessment represented a significant step forward in the
understanding of shortfin mako populations in the Atlantic Ocean.},
  language = {en},
  number = {4},
  journal = {Collect. Vol. Sci. Pap. ICCAT},
  author = {ICCAT},
  year = {2017},
  keywords = {⛔ No DOI found},
  pages = {1465-1561},
  file = {/home/jkbest/Dropbox/Zotero/storage/HJ66FUK3/ICCAT - 2017 - Report of the 2017 ICCAT shortfin mako stock assessment meeting.pdf}
}

@article{ICCAT2017a,
  title = {Report of the 2017 {{ICCAT Atlantic}} Swordfish Stock Assessment Session},
  volume = {74},
  abstract = {The meeting was held in Madrid Spain, 12-16 June. The objective of this meeting was to assess
the status of the stocks (North and South) of Atlantic shortfin mako shark. The last assessment
was conducted in 2012. The populations were assessed using several models, from different types
of surplus production models to fully integrated age-structured models. For the first time,
projections of stock status were conducted for this species and management advice was provided
based on Kobe strategy matrices. The assessment represented a significant step forward in the
understanding of shortfin mako populations in the Atlantic Ocean.},
  language = {en},
  number = {3},
  journal = {Collect. Vol. Sci. Pap. ICCAT},
  author = {ICCAT},
  year = {2017},
  keywords = {⛔ No DOI found},
  pages = {841-967},
  file = {/home/jkbest/Dropbox/Zotero/storage/JGE5NDUN/ICCAT - 2017 - Report of the 2017 ICCAT Atlantic swordfish stock assessment session.pdf}
}

@article{ICCAT2017,
  title = {Report of the 2017 {{ICCAT}} Albacore Species Group Intersessional Meeting (Including Assessment of {{Mediterranean}} Albacore)},
  volume = {74},
  abstract = {An ICCAT Albacore species group intersessional meeting was held in Madrid, Spain, 5-9 June
2017. The Group produced a stock assessment for the Mediterranean stock (last assessed in
2011), based on data poor methods. Likewise, substantial progress was made by the Group on
the development of the MSE framework, namely testing Limit Reference Points and HCRs for
north Atlantic albacore, and improved CPUE series for both northern and southern Albacore.},
  language = {en},
  number = {2},
  journal = {Collect. Vol. Sci. Pap. ICCAT},
  author = {ICCAT},
  year = {2017},
  keywords = {⛔ No DOI found},
  pages = {508-583},
  file = {/home/jkbest/Dropbox/Zotero/storage/MV4ZCZL6/ICCAT - 2017 - Report of the 2017 ICCAT albacore species group intersessional meeting.pdf}
}

@article{ICCAT2014,
  title = {Report of the 2013 {{Atlantic}} Swordfish Stock Assessment Session},
  volume = {70},
  abstract = {Atlantic Swordfish Stock Assessment Session. The meeting was held in Olhȧo, Portugal, 2-10
September 2013. The objective of the meeting was to carry out stock assessments of the North
and South Atlantic swordfish stocks.},
  language = {en},
  number = {2},
  journal = {Collect. Vol. Sci. Pap. ICCAT},
  author = {ICCAT},
  year = {2014},
  keywords = {⛔ No DOI found},
  pages = {1484-1678},
  file = {/home/jkbest/Dropbox/Zotero/storage/J6UN3JK3/ICCAT - 2014 - Report of the 2013 Atlantic swordfish stock assessment session.pdf}
}

@article{CarvalhoEtAl2014,
  title = {Incorporating Specific Change Points in Catchability in Fisheries Stock Assessment Models: {{An}} Alternative Approach Applied to the Blue Shark ({{Prionace}} Glauca) Stock in the South {{Atlantic Ocean}}},
  volume = {154},
  issn = {0165-7836},
  shorttitle = {Incorporating Specific Change Points in Catchability in Fisheries Stock Assessment Models},
  abstract = {Fishermen frequently switch their target fish species without documenting changes in which species they are targeting and the fishing practices used, generating misleading catchability information about the fish caught. To date, changes in target species have been incorporated in stock assessments at two different levels in analyses. First, these changes are taken into account during the parameterization of generalized linear models used to compute the CPUE index standardization. Second, changes in target species are directly incorporated as a time-varying catchability parameter during the fitting of the dynamic model used for the assessment. Here, we present an alternative method for this incorporation by specifying a single change point in the stationary distribution of the catchability coefficient in a Bayesian state-space production model. Two models were fitted to the time series of the south Atlantic blue shark (Prionace glauca) stock. In one of the models, only one catchability coefficient was estimated. In the other model, a change point was included, and two catchability coefficients were estimated, one before the change point, and the other after. Despite the latter model introducing an extra parameter, it produced a significantly better fit than the modeling approach without the change point. Although including a single change point in the catchability coefficient had no significant impact on the status of south Atlantic blue shark (which is still above BMSY), it provided a robust way of accounting for changes in catchability as a result of fishermen changing target species.},
  journal = {Fish. Res.},
  doi = {10.1016/j.fishres.2014.01.022},
  author = {Carvalho, Felipe and Ahrens, Robert and Murie, Debra and Ponciano, Jos{\'e} M. and {Aires-da-Silva}, Alexandre and Maunder, Mark N. and Hazin, F{\'a}bio},
  month = jun,
  year = {2014},
  keywords = {Stock assessment,CPUE standardization,Blue shark,Catchability,South Atlantic},
  pages = {135-146},
  file = {/home/jkbest/Dropbox/Zotero/storage/V27CJ5NI/Carvalho et al. - 2014 - Incorporating specific change points in catchability in fisheries stock.pdf}
}

@article{ChangEtAl2015,
  series = {Proceedings of the 5th {{International Billfish Symposium}}},
  title = {Model Selection and Multi-Model Inference for {{Bayesian}} Surplus Production Models: A Case Study for {{Pacific}} Blue and Striped Marlin},
  volume = {166},
  issn = {0165-7836},
  shorttitle = {Model Selection and Multi-Model Inference for {{Bayesian}} Surplus Production Models},
  abstract = {Stock assessment typically involves developing a set of alternative models, fitting each to the available data, and then selecting the one that gives the most accurate estimates of management quantities of interest. In this context, it is important to consider model selection uncertainty because ignoring it can lead to unreliable estimates and overconfident inferences. For this study, four Bayesian surplus production models with symmetric or asymmetric production functions and either a constant or hierarchical time-varying intrinsic growth rate (r) were developed using data for Pacific blue marlin (Makaira nigricans) and Western and Central North Pacific striped marlin (Kajikia audax). The uncertainty resulting from model selection was evaluated using Monte Carlo simulation techniques to examine the consistency of model estimates within (self-tests) and among (cross-tests) the alternative models. Specifically, these tests evaluated the performance of the deviance information criterion (DIC) and Bayesian model averaging (BMA). The results of the simulation tests suggested that mis-specification of time-varying r can lead to large estimation errors for biomass and management quantities and that DIC may not reliably identify the true data-generating model. Although BMA did not provide more accurate point estimates than just selecting the data-generating model, it did provide a more accurate characterization of uncertainty in model results. Our study shows the value of using simulations to evaluate model performance and to account for model selection uncertainty.},
  journal = {Fish. Res.},
  doi = {10.1016/j.fishres.2014.08.023},
  author = {Chang, Yi-Jay and Brodziak, Jon and O'Malley, Joseph and Lee, Hui-Hua and DiNardo, Gerard and Sun, Chi-Lu},
  month = jun,
  year = {2015},
  keywords = {Multi-model inference,Deviance information criterion,Bayesian hierarchical surplus production model,Billfish,Model selection uncertainty},
  pages = {129-139},
  file = {/home/jkbest/Dropbox/Zotero/storage/T8YRYB9Z/Chang et al. - 2015 - Model selection and multi-model inference for Bayesian surplus production models.pdf}
}

@article{McAllister2014,
  title = {A Generalized {{Bayesian}} Surplus Production Stock Assessment Software ({{BSP2}})},
  volume = {70},
  abstract = {A generalized Bayesian surplus production stock assessment software (BSP2) is presented as an update to ICCAT's current BSP software. BSP2 differs from BSP in a few different respects. Most importantly, BSP2 provides a state-space implementation of the deterministic Bayesian generalized surplus production model found in BSP. BSP2 models both process error in the dynamics equations to account for the effects of, e.g., interannual variation in recruitment, and error in predicted observations. BPS2 provides outputs to enable the computation of Bayes factors (BFs). BFs show Bayes posterior weights for different models and can be particularly important when structurally different models suggest different interpretations of stock status. A generalized production function implementation (i.e., the Fletcher model) is incorporated in which the ratio of the most productive stock size to carrying capacity can be set at hypothesized values other than the Schaefer model value of 0.5. The software can accommodate a variety of different priors for key parameters including carrying capacity (K), the maximum rate of population increase (r), and the ratio of stock biomass in the initial year to carrying capacity (Binit/K).},
  language = {en},
  number = {4},
  journal = {Collect. Vol. Sci. Pap. ICCAT},
  author = {McAllister, Murdoch K},
  year = {2014},
  keywords = {⛔ No DOI found},
  pages = {1725-1757},
  file = {/home/jkbest/Dropbox/Zotero/storage/CR98V4BW/McAllister - 2014 - A generalized Bayesian surplus production stock assessment software (BSP2).pdf}
}

@article{Prager2002,
  title = {Comparison of Logistic and Generalized Surplus-Production Models Applied to Swordfish, {{Xiphias}} Gladius, in the North {{Atlantic Ocean}}},
  volume = {58},
  issn = {0165-7836},
  abstract = {Recent assessments of swordfish, Xiphias gladius, in the north Atlantic Ocean by the International Commission for the Conservation of Atlantic Tunas (ICCAT) have included fitting a nonequilibrium logistic (Schaefer) surplus-production model. The logistic model offers simplicity, but concern has been expressed that its fixed model shape may bias estimates of quantities of management interest. Here, I compare results from the logistic estimator used by ICCAT to those from an otherwise equivalent generalized (Pella\textendash{}Tomlinson) production-model estimator. Following initial estimation with nonlinear least-squares, a resistant fitting method was used to identify statistical outliers, and both models were refit with outliers removed. The estimate of model shape from the generalized model was then close to the logistic, and estimates of stock status from the two estimators were similar. A simulation study conditioned on the trimmed generalized fit suggests that any systematic estimation error caused by assuming logistic shape for this stock is small. Moreover, the generalized estimator was sensitive to outlying observations and thus less precise than the logistic estimator, and it exhibited larger median proportional unsigned error. Sensitivity to outliers and lack of precision in an estimator make it more likely to provide misleading estimates in a given analysis; therefore, if the generalized production model with estimated shape parameter is used in stock assessment, it should be applied with skepticism and in conjunction with the more robust logistic form. Unless a good external estimate of model shape is available, the logistic model appears more suitable for routine assessment use on stocks similar to swordfish.},
  number = {1},
  journal = {Fish. Res.},
  doi = {10.1016/S0165-7836(01)00358-7},
  author = {Prager, Michael H.},
  month = oct,
  year = {2002},
  keywords = {Stock assessment,Swordfish,Accuracy,North Atlantic Ocean,Outliers,Precision,Robust methods,Surplus production},
  pages = {41-57},
  file = {/home/jkbest/Dropbox/Zotero/storage/SXBSG7VE/Prager - 2002 - Comparison of logistic and generalized surplus-production models applied to.pdf;/home/jkbest/Dropbox/Zotero/storage/PG23AZH7/S0165783601003587.html}
}

@article{LunnEtAl2009,
  title = {The {{BUGS}} Project: {{Evolution}}, Critique and Future Directions},
  volume = {28},
  copyright = {Copyright \textcopyright{} 2009 John Wiley \& Sons, Ltd.},
  issn = {1097-0258},
  shorttitle = {The {{BUGS}} Project},
  abstract = {BUGS is a software package for Bayesian inference using Gibbs sampling. The software has been instrumental in raising awareness of Bayesian modelling among both academic and commercial communities internationally, and has enjoyed considerable success over its 20-year life span. Despite this, the software has a number of shortcomings and a principal aim of this paper is to provide a balanced critical appraisal, in particular highlighting how various ideas have led to unprecedented flexibility while at the same time producing negative side effects. We also present a historical overview of the BUGS project and some future perspectives. Copyright \textcopyright{} 2009 John Wiley \& Sons, Ltd.},
  language = {en},
  number = {25},
  journal = {Stat. Med.},
  doi = {10.1002/sim.3680},
  author = {Lunn, David and Spiegelhalter, David and Thomas, Andrew and Best, Nicky},
  year = {2009},
  keywords = {WinBUGS,BUGS,OpenBUGS,Bayesian modelling,graphical models},
  pages = {3049-3067},
  file = {/home/jkbest/Dropbox/Zotero/storage/FIHGE3QF/Lunn et al. - 2009 - The BUGS project.pdf}
}

@article{ZerbiniEtAl2011,
  title = {A {{Bayesian}} Assessment of the Conservation Status of Humpback Whales ({{Megaptera}} Novaeangliae) in the Western {{South Atlantic Ocean}}},
  volume = {Special Issue 3},
  abstract = {The population of humpback whales (Megaptera novaeangliae) wintering off the eastern coast of South America is referred to by the International Whaling Commission as `Breeding Stock A' (BSA). This population was heavily exploited in 20th century modern commercial whaling operations. After more than 30 years of protection, its present status remains unknown. A deterministic sex and age-aggregated population dynamics model was used to estimate the pre-exploitation population size (K), the maximum net recruitment rate (rmax), the maximum depletion level (Nmin/K), and other quantities of interest of BSA. Input data included modern whaling catch series, absolute estimates of abundance, observed growth rates and indices of relative abundance. A Bayesian statistical method was used to calculate probability distributions for the model parameters. Prior distributions were set on rmax \textendash{} an uninformative (Uniform [0, 0.106]) and an informative (Normal [0.067, 0.042]) \textendash{} and on the population size in 2005 \textendash{} N2005 (Uniform [500, 22,000]). A total of 10,000 samples were used to compute the joint posterior distribution of the model parameters using the Sampling-Importance-Resampling algorithm. Sensitivity of model outputs to the priors on rmax, a genetic constraint, data inclusion and catch allocation scenarios was investigated. Medians of the posterior probability distributions of quantities of interest for the base case scenario were: rmax = 0.069 (95\% probability intervals [PI] = 0.013\textendash{}0.104), K = 24,558 (95\% PI = 22,791\textendash{}31,118), Nmin/K = 2\% (PI = 0.31\%\textendash{}12.5\%), N2006/ K = 27.4\% (PI = 18.3\%\textendash{}39.5\%), N2020/K = 61.8\% (PI = 23.8\%\textendash{}88.6\%), and N2040/K = 97.3\% (PI = 31.6\%\textendash{}99.9\%). Despite apparent recovery in the past three decades, the western South Atlantic humpback whale population is still low relative to its pre-exploitation size and requires continued conservation efforts.},
  language = {en},
  number = {3},
  journal = {J. Cetacean Res. Manage.},
  author = {Zerbini, Alexandre N and Ward, Eric J and Kinas, Paul G and Engel, M{\'a}rcia H and Andriolo, Artur},
  year = {2011},
  keywords = {⛔ No DOI found},
  pages = {131-144},
  file = {/home/jkbest/Dropbox/Zotero/storage/IAUDV6KA/Zerbini et al. - 2011 - A Bayesian assessment of the conservation status of humpback whales (Megaptera.pdf}
}

@article{Prager1992,
  title = {{{ASPIC}} - a Surplus-Production Model Incorporating Covariates},
  volume = {38},
  abstract = {Surplus-production modeling has often assumed equilibrium conditions, although stocks are rarely thought to be in equilibrium. This paper describes a simple non-equilibrium approach (ASPIC) to fitting a logistic production model to catch and effort data. From such data, ASPIC provides estimates of the two logistic parameters r and K , catchability q, and stock biomass B\textsubscript{t} in the first year of the time series. From these four quantities, estimates can be made of MSY, stock size at MSY, optimal effort at MSY, optimal fishing mortality at MSY, and the time series of stock biomass levels, surplus production levels, and fishing mortality levels. he general optimization approach is similar to that used by Pella and Timplinson in their GENPROD computer program; however ASPIC uses an analytical solution of the yield equation, a revised loss function , and incorporates several other refinements including bootstrap estimates of variability. The method handles missing data (years with no fishery) correctly without modification and is extremely flexible in handling different patterns of fishing, such a (i) two or more simultaneous fisheries with different types of gear (ii) a fishery that ends and then resumes with a different type of gear, (iii) density-dependent catchability; and (iv) time trends in catchability. The model can be adapted easily to use auxiliary information (e.g. external estimates of population biomass) to tune the model. The major advantages of the ASPIC model are as follows; it is a true non-solution of the production equations; it retains true population persistence; it eliminates the need to use catch-per-unit-effort as an index of abundance, a practive that has been criticized on statistical grounds; and it can be modified easily. The paper describes the structure of the model and its performance on several simulated and real data sets.},
  language = {en},
  journal = {Collect. Vol. Sci. Pap. ICCAT},
  author = {Prager, Michael H.},
  year = {1992},
  keywords = {⛔ No DOI found},
  pages = {218-229},
  file = {/home/jkbest/Dropbox/Zotero/storage/LXP8RZR6/Prager - 1992 - ASPIC - a surplus-production model incorporating covariates.pdf}
}

@misc{RStan,
  title = {{{RStan}}: The {{R}} Interface to {{Stan}}},
  author = {{Stan Development Team}},
  year = {2018}
}

@techreport{BrodziakEtAl2001,
  address = {{Woods Hole, MA}},
  type = {Reference {{Document}}},
  title = {Assessment of the Silver Hake Resource in the {{Northwest Atlantic}} in 2000: {{A}} Report of the 32nd {{Northeast Regional Stock Assessment Workshop}}},
  shorttitle = {Assessment of the Silver Hake Resource in the {{Northwest Atlantic}} in 2000},
  language = {en},
  number = {01-03},
  institution = {{Northeast Fisheries Science Center, NMFS}},
  author = {Brodziak, Jon K. T. and Holmes, Elizabeth M. and Sosebee, Katherine A. and Mayo, Ralph K.},
  month = mar,
  year = {2001},
  pages = {142},
  file = {/home/jkbest/Dropbox/Zotero/storage/CJ37V3MF/Brodziak et al. - 2001 - Assessment of the silver hake resource in the Northwest Atlantic in 2000.pdf}
}

@article{Silliman1971,
  title = {Advantages and Limitations of "Simple" Fishery Models in Light of Laboratory Experiments},
  volume = {28},
  issn = {0015-296X},
  abstract = {"Simple" fishery models as treated herein are those requiring only catch and effort data for fitting. In the models described, the yield-on-biomass curve is considered equivalent to the growth curve of the population: Schaefer, logistic; Fox, Gompertz; Pella and Tomlinson, generalized. The Fox model is more realistic for fish populations than the Schaefer, eliminating the constraint of a symmetrical yield curve. The Pella\textendash{}Tomlinson model is general, including the others as special instances. Tests against data from laboratory populations of guppies support the validity of the Fox and Pella\textendash{}Tomlinson models. The Fox model is the simpler to fit of the two (as it has less parameters) and has been shown to be appropriate for a number of commercial fisheries. Advantages of the models include their minimal requirements for basic data and relative ease of fitting. Limitations include lack of provision for reproductive lag and waste of biological information other than catch and effort., non disponible},
  number = {8},
  journal = {J. Fish. Res. Bd. Can.},
  doi = {10.1139/f71-182},
  author = {Silliman, R. P.},
  month = aug,
  year = {1971},
  pages = {1211-1214},
  file = {/home/jkbest/Dropbox/Zotero/storage/WQA8N5GC/Silliman - 1971 - Advantages and limitations of simple fishery models in light of laboratory.pdf}
}

@misc{SpiegelhalterEtAl2003,
  title = {{{WinBUGS User Manual}}},
  author = {Spiegelhalter, David J. and Thomas, Andrew and Best, Nicholas and Lunn, David J.},
  month = jan,
  year = {2003},
  file = {/home/jkbest/Dropbox/Zotero/storage/NAZCC3BM/Spiegelhalter et al. - 2003 - WinBUGS User Manual.pdf}
}

@techreport{BullEtAl2012,
  address = {{Wellington, New Zealand}},
  type = {{{NIWA Technical Report}}},
  title = {{{CASAL}} ({{C}}++ Algorithmic Stock Assessment Laboratory) {{CASAL User Manual}} v2.30-2012/03/2},
  shorttitle = {{{CASAL User Manual}}},
  language = {en},
  number = {135},
  author = {Bull, B. and Francis, R.I.C.C. and Dunn, A. and McKenzie, A. and Gilbert, D.J. and Smith, M.H. and Bian, R. and Fu, D.},
  month = mar,
  year = {2012},
  pages = {280},
  file = {/home/jkbest/Dropbox/Zotero/storage/K83TLKRP/Bull et al. - 2012 - CASAL (C++ algorithmic stock assessment laboratory) CASAL User Manual v2.pdf},
  note = {ISSN 1174-2631}
}

@article{PedersenBerg2017,
  title = {A Stochastic Surplus Production Model in Continuous Time},
  volume = {18},
  copyright = {\textcopyright{} 2016 John Wiley \& Sons Ltd},
  issn = {1467-2979},
  abstract = {Surplus production modelling has a long history as a method for managing data-limited fish stocks. Recent advancements have cast surplus production models as state-space models that separate random variability of stock dynamics from error in observed indices of biomass. We present a stochastic surplus production model in continuous time (SPiCT), which in addition to stock dynamics also models the dynamics of the fisheries. This enables error in the catch process to be reflected in the uncertainty of estimated model parameters and management quantities. Benefits of the continuous-time state-space model formulation include the ability to provide estimates of exploitable biomass and fishing mortality at any point in time from data sampled at arbitrary and possibly irregular intervals. We show in a simulation that the ability to analyse subannual data can increase the effective sample size and improve estimation of reference points relative to discrete-time analysis of aggregated annual data. Finally, subannual data from five North Sea stocks are analysed with particular focus on using residual analysis to diagnose model insufficiencies and identify necessary model extensions such as robust estimation and incorporation of seasonality. We argue that including all known sources of uncertainty, propagation of that uncertainty to reference points and checking of model assumptions using residuals are critical prerequisites to rigorous fish stock management based on surplus production models.},
  language = {en},
  number = {2},
  journal = {Fish and Fisheries},
  doi = {10.1111/faf.12174},
  author = {Pedersen, Martin W. and Berg, Casper W.},
  year = {2017},
  keywords = {stock assessment,fisheries management,Data-limited methods,maximum sustainable yield,Pella–Tomlinson model,seasonal population dynamics},
  pages = {226-243},
  file = {/home/jkbest/Dropbox/Zotero/storage/4QTE3N58/Pedersen and Berg - 2017 - A stochastic surplus production model in continuous time.pdf}
}

@article{RivardBledsoe1978,
  title = {Parameter Estimation for the {{Pella}}-{{Tomlinson}} Model under Nonequilibrium Conditions},
  volume = {76},
  abstract = {To estimate the parameters of the Pella-Tomlinson model, as restructured by Fletcher in this issue, we suggest a derivative-free version ofthe Levenberg-Marquardt algorithm, along with an algorithm that locates starting values for the iterative procedure. The iterative method of Levenberg-Marquardt was applied to two versions of the restructured model: five parameters were estimated in the first version and three in the second, the latter preventing degeneracy of the model to exponential form. We discuss in particular the causes of the degeneracies associated with previous applications of the model. Such faults lie, inherently, with the mathematical indeterminacy of the system equations themselves, so that all nonlinear estimation methods will tend to be inefficient in the absence of external constraints. The effectiveness of the Levenberg-Marquardt method was eva'\textbackslash{}uated by Monte-Carlo simulation. As examples, we analyzed catch-effort data from the yellowfin tuna fishery of the eastern Pacific and catch-effort data from the Pacific halibut fishery (Area 2 of the International Pacific Halibut Commission).},
  language = {en},
  number = {3},
  journal = {Fish. Bull.},
  author = {Rivard, D and Bledsoe, L J},
  year = {1978},
  keywords = {⛔ No DOI found},
  pages = {523-355},
  file = {/home/jkbest/Dropbox/Zotero/storage/KXL435WF/Rivard and Bledsoe - 1978 - Parameter estimation for the Pella-Tomlinson model under nonequilibrium.pdf}
}

@article{CadiganEtAl2017,
  title = {A Spatiotemporal Model for Snow Crab ({{Chionoecetes}} Opilio) Stock Size in the Southern {{Gulf}} of {{St}}. {{Lawrence}}},
  volume = {74},
  issn = {0706-652X},
  abstract = {We develop a high-resolution spatiotemporal model of stock size and harvest rates for snow crab (Chionoecetes opilio) in the southern Gulf of St. Lawrence, which supports an economically important fishery off the east coast of Canada. It is a spatial and weekly model during 1997\textendash{}2014 that utilizes within-season depletion based on catch per unit of effort (CPUE; kg{$\cdot$}pot\textendash{}1) and also biomass values from a survey designed specifically for this stock. The model is formulated in a state-space framework. The main contribution of the model is to provide a better understanding of fishery-dependent factors that affect CPUE. There is strong evidence of density dependence in the relationship with CPUE and stock biomass, in addition to a general increase in CPUE catchability over time that may be related to changes in gear soak time and spatial variation in catchability. We also find that a natural mortality rate of 0.4 provides a better fit to survey results. Model results suggest that there is no evidence of effort saturation in the fishery.},
  number = {11},
  journal = {Can. J. Fish. Aquat. Sci.},
  doi = {10/gf6rjs},
  author = {Cadigan, Noel G. and Wade, Elmer and Nielsen, Anders},
  month = jan,
  year = {2017},
  pages = {1808-1820},
  file = {/home/jkbest/Dropbox/Zotero/storage/I9XZ98AK/Cadigan et al. - 2017 - A spatiotemporal model for snow crab (Chionoecetes opilio) stock size in the.pdf}
}

@article{AlbertsenEtAl2017,
  title = {Choosing the Observational Likelihood in State-Space Stock Assessment Models},
  volume = {74},
  issn = {0706-652X},
  abstract = {Data used in stock assessment models result from combinations of biological, ecological, fishery, and sampling processes. Since different types of errors propagate through these processes, it can be difficult to identify a particular family of distributions for modelling errors on observations a priori. By implementing several observational likelihoods, modelling both numbers- and proportions-at-age, in an age-based state-space stock assessment model, we compare the model fit for each choice of likelihood along with the implications for spawning stock biomass and mean fishing mortality. We propose using AIC intervals based on fitting the full observational model for comparing different observational likelihoods. Using data from four stocks, we show that the model fit is improved by modelling the correlation of observations within years. However, the best choice of observational likelihood differs for different stocks, and the choice is important for the short-term conclusions drawn from the assessment model; in particular, the choice can influence total allowable catch advise based on reference points.},
  number = {5},
  journal = {Can. J. Fish. Aquat. Sci.},
  doi = {10/gf6rjt},
  author = {Albertsen, Christoffer Moesgaard and Nielsen, Anders and Thygesen, Uffe H{\o}gsbro},
  year = {2017},
  pages = {779-789},
  file = {/home/jkbest/Dropbox/Zotero/storage/4H5F3WE4/Albertsen et al. - 2017 - Choosing the observational likelihood in state-space stock assessment models.pdf}
}

@article{Bousquet2010,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1007.5388},
  primaryClass = {math, stat},
  title = {Reference Priors of Nuisance Parameters in {{Bayesian}} Sequential Population Analysis},
  abstract = {Prior distributions elicited for modelling the natural fluctuations or the uncertainty on parameters of Bayesian fishery population models, can be chosen among a vast range of statistical laws. Since the statistical framework is defined by observational processes, observational parameters enter into the estimation and must be considered random, similarly to parameters or states of interest like population levels or real catches. The former are thus perceived as nuisance parameters whose values are intrinsically linked to the considered experiment, which also require noninformative priors. In fishery research Jeffreys methodology has been presented by Millar (2002) as a practical way to elicit such priors. However they can present wrong properties in multiparameter contexts. Therefore we suggest to use the elicitation method proposed by Berger and Bernardo to avoid paradoxical results raised by Jeffreys priors. These benchmark priors are derived here in the framework of sequential population analysis.},
  journal = {arXiv:1007.5388 [math, stat]},
  author = {Bousquet, Nicolas},
  month = jul,
  year = {2010},
  keywords = {Mathematics - Statistics Theory,⛔ No DOI found},
  file = {/home/jkbest/Dropbox/Zotero/storage/PEZQZUS4/Bousquet - 2010 - Reference priors of nuisance parameters in Bayesian sequential population.pdf}
}

@article{WardEtAl2019,
  title = {Modeling Regimes with Extremes: The Bayesdfa Package for Identifying and Forecasting Common Trends and Anomalies in Multivariate Time-Series Data},
  issn = {2073-4859},
  shorttitle = {Modeling Regimes with Extremes},
  abstract = {The bayesdfa package provides a flexible Bayesian modeling framework for applying dynamic factor analysis (DFA) to multivariate time-series data as a dimension reduction tool. The core estimation is done with the Stan probabilistic programming language. In addition to being one of the few Bayesian implementations of DFA, novel features of this model include (1) optionally modeling latent process deviations as drawn from a Student-t distribution to better model extremes, and (2) optionally including autoregressive and moving-average components in the latent trends. Besides estimation, we provide a series of plotting functions to visualize trends, loadings, and model predicted values. A secondary analysis for some applications is to identify regimes in latent trends. We provide a flexible Bayesian implementation of a Hidden Markov Model \textemdash{} also written with Stan \textemdash{} to characterize regime shifts in latent processes. We provide simulation testing and details on parameter sensitivities in supplementary information.},
  language = {en},
  journal = {The R Journal},
  author = {Ward, Eric J. and Anderson, Sean C. and Damiano, Luis A. and Hunsicker, Mary E. and Litzow, Michael A.},
  year = {2019},
  keywords = {⛔ No DOI found},
  file = {/home/jkbest/Dropbox/Zotero/storage/XUKERRBL/Ward et al. - Modeling regimes with extremes the bayesdfa packa.pdf},
  ids = {WardEtAl}
}

@article{Punt1990,
  title = {Is {{B}} 1 = {{K}} an Appropriate Assumption When Applying an Observation Error Production-Model Estimator to Catch-Effort Data?},
  volume = {9},
  issn = {0257-7615},
  abstract = {A Monte-Carlo simulation approach is used to investigate the relative robustness of the results of the Butterworth\textendash{}Andrew (B 1 = K and B 1 estimated) dynamic production-model observation-error estimators to different "true" values of the ratio of initial biomass B 1 to unexploited equilibrium biomass K. The simulations use an underlying operating model typical of that appropriate for stocks of Cape hake off southern Africa. The B 1 = K variant of the estimator results in lower estimated expected discrepancies for a number of management quantities over a wide range of the value of the "true" ratio. In addition, it is less likely to provide severe overestimates of the f 0.1 total allowable catch (TAC). Not all management quantities are equally sensitive to the value of the "true" ratio. In particular, f 0.1) TACs can be severely overestimated, although the maximum sustainable yield (MSY) is relatively well determined over a wide range of values of the ratio. It is therefore recommended that harvesting strategies which do not permit TACs to be set in excess of the estimated MSY be preferred.},
  number = {1},
  journal = {South African Journal of Marine Science},
  doi = {10.2989/025776190784378925},
  author = {Punt, A. E.},
  month = jun,
  year = {1990},
  pages = {249-259},
  file = {/home/jkbest/Dropbox/Zotero/storage/KDXHCBR2/Punt - 1990 - Is B 1 = K an appropriate assumption when applying an observation error.pdf}
}

@article{Gudmundsson1994,
  title = {Time {{Series Analysis}} of {{Catch}}-{{At}}-{{Age Observations}}},
  volume = {43},
  copyright = {\textcopyright{} 1994 Royal Statistical Society},
  issn = {1467-9876},
  abstract = {Catches, stocks and fishing mortality rates are connected by given non-linear relationships. Multivariate time series models of fishing mortality rates are proposed and linear approximations to the Kalman filter algorithm are used to estimate the unobserved series of stocks and fishing mortality rates from observed series of catches at each age. The model parameters are estimated by the likelihood function of the catch prediction errors. Time series estimation does not require fishing effort measurements as well as the catch-at-age data, but it is also possible to include auxiliary information. Estimates of stocks and fishing mortality rates with acceptable accuracy can be obtained from exceptionally short series. They are not unduly sensitive to misspecifications and inaccurate estimation of model parameters.},
  language = {en},
  number = {1},
  journal = {Journal of the Royal Statistical Society: Series C (Applied Statistics)},
  doi = {10.2307/2986116},
  author = {Gudmundsson, Gudmundur},
  year = {1994},
  keywords = {Fish stock assessment,Kalman filter,Catch at age,State-dependent models,Structural time series analysis},
  pages = {117-126}
}

@article{CoppolaPascoe1998,
  title = {A Surplus Production Model with a Nonlinear Catch-Effort Relationship},
  volume = {13},
  issn = {0738-1360},
  abstract = {Surplus production models have been used in fisheries analysis for over 40 years. The traditional surplus production model incorporates the assumption that catch per unit of effort is constant for a given stock size. As a result, effort can be indefinitely applied to the fishery in the short term, and catch would indefinitely increase at a constant rate. In this paper, a surplus production bioeconomic model is developed using a nonlinear form of the short-run catch equation based on the Spillman production function. Two long-run models were derived using the logistic and exponential growth models. The parameters for the long-run equilibrium models are estimated from catch and effort data using a disequilibrium form of the model. The models were applied to data for the Hawaiian lobster fishery used in the analysis by Clarke, Yoshimoto, and Pooley (1992). The results were compared with the results derived from conventional forms of the surplus production model. The key parameter values were similar to those reported by Clarke, Yoshimoto, and Pooley, but the amount of variation in the data explained by the new formulation of the models was generally higher.},
  number = {1},
  journal = {Marine Resource Economics},
  doi = {10.1086/mre.13.1.42629217},
  author = {Coppola, Gianluigi and Pascoe, Sean},
  month = apr,
  year = {1998},
  pages = {37-50},
  file = {/home/jkbest/Dropbox/Zotero/storage/AYHZL77U/Coppola and Pascoe - 1998 - A surplus production model with a nonlinear catch-effort relationship.pdf},
  ids = {COPPOLAPASCOE1998}
}

@article{RankinLemos2015,
  title = {An Alternative Surplus Production Model},
  volume = {313},
  issn = {0304-3800},
  abstract = {In this work we present a novel surplus production model for fisheries stock assessment. Our goal is to enhance parameter estimation and fitting speed. The model employs a production function that differs from the canonical logistic (Schaefer) and Gompertz (Fox) functions, but is still connected to the Pella\textendash{}Tomlinson formulation. We embed this function in a state-space model, using observed catch-per-unit-effort indices and measures of fishing effort as input. From the literature we derive Bayesian prior densities for all model hyperparameters (carrying capacity, catchability, growth rate and error variance), as well as the state (annual stock biomass). We use the well-studied Namibian hake fishery as a case study, via which we compare the Schaefer, Fox and Pella\textendash{}Tomlinson models with the new model. We also develop a package for the software R, which employs a Shiny application for data exploration, model specification, and output analyses. Posterior densities of hyperparameters and reference points agree across models. Identifiability issues emerge in the more cumbersome Pella\textendash{}Tomlinson model. The new model yields small but consistent improvements in precision. It also renders implementation faster and easier, with no hidden truncation of negative biomasses. We conclude by discussing theoretical and practical extensions to this new model.},
  journal = {Ecological Modelling},
  doi = {10.1016/j.ecolmodel.2015.06.024},
  author = {Rankin, Peter Sheldon and Lemos, Ricardo T.},
  month = oct,
  year = {2015},
  keywords = {Bayesian inference,Stock assessment,Surplus production model,Fisheries models,Management reference points},
  pages = {109-126}
}

@article{BordetRivest2014,
  title = {A Stochastic {{Pella Tomlinson}} Model and Its Maximum Sustainable Yield},
  volume = {360},
  issn = {0022-5193},
  abstract = {This paper investigates the biological reference points, such as the maximum sustainable yield (MSY), for the Pella Tomlinson and the Fox surplus production models (SPM) in the presence of a multiplicative environmental noise. These models are used in fisheries stock assessment as a firsthand tool for the elaboration of harvesting strategies. We derive conditions on the environmental noise distribution that insure that the biomass process for an SPM has a stationary distribution, so that extinction is avoided. Explicit results about the stationary behavior of the biomass distribution are provided for a particular specification of the noise. The consideration of random noise in the MSY calculations leads to more conservative harvesting target than deterministic models. The derivations account for a possible noise autocorrelation that represents the occurrence of spells of good and bad years. The impact of the noise is found to be more severe on Pella Tomlinson model for which the asymmetry parameter p is large while it is less important for Fox model.},
  journal = {Journal of Theoretical Biology},
  doi = {10.1016/j.jtbi.2014.06.012},
  author = {Bordet, Charles and Rivest, Louis-Paul},
  month = nov,
  year = {2014},
  keywords = {Surplus production model,Markov chain,Beta distribution,Fox model},
  pages = {46-53},
  file = {/home/jkbest/Dropbox/Zotero/storage/JBEDQ58Y/Bordet and Rivest - 2014 - A stochastic Pella Tomlinson model and its maximum sustainable yield.pdf}
}

@article{LenziEtAl2019,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1907.06932},
  primaryClass = {stat},
  title = {Improving {{Bayesian Local Spatial Models}} in {{Large Data Sets}}},
  abstract = {Environmental processes resolved at a sufficiently small scale in space and time will inevitably display non-stationary behavior. Such processes are both challenging to model and computationally expensive when the data size is large. Instead of modeling the global non-stationarity explicitly, local models can be applied to disjoint regions of the domain. The choice of the size of these regions is dictated by a bias-variance trade-off; large regions will have smaller variance and larger bias, whereas small regions will have higher variance and smaller bias. From both the modeling and computational point of view, small regions are preferable to better accommodate the non-stationarity. However, in practice, large regions are necessary to control the variance. We propose a novel Bayesian three-step approach that allows for smaller regions without compromising the increase of the variance that would follow. We are able to propagate the uncertainty from one step to the next without issues caused by reusing the data. The improvement in inference also results in improved prediction, as our simulated example shows. We illustrate this new approach on a data set of simulated high-resolution wind speed data over Saudi Arabia.},
  language = {en},
  journal = {arXiv:1907.06932 [stat]},
  author = {Lenzi, Amanda and Castruccio, Stefano and Rue, Haavard and Genton, Marc G.},
  month = jul,
  year = {2019},
  keywords = {Statistics - Applications,⛔ No DOI found},
  file = {/home/jkbest/Dropbox/Zotero/storage/LQKRGZA3/Lenzi et al. - 2019 - Improving Bayesian Local Spatial Models in Large D.pdf}
}

@article{LiuEtAl2019a,
  title = {Exploring Spatial Nonstationary Environmental Effects on {{Yellow Perch}} Distribution in {{Lake Erie}}},
  volume = {7},
  issn = {2167-8359},
  abstract = {Background: Global regression models under an implicit assumption of spatial stationarity were commonly applied to estimate the environmental effects on aquatic species distribution. However, the relationships between species distribution and environmental variables may change among spatial locations, especially at large spatial scales with complicated habitat. Local regression models are appropriate supplementary tools to explore species-environment relationships at finer scales.
Method: We applied geographically weighted regression (GWR) models on Yellow Perch in Lake Erie to estimate spatially-varying environmental effects on the presence probabilities of this species. Outputs from GWR were compared with those from generalized additive models (GAMs) in exploring the Yellow Perch distribution. Local regression coefficients from the GWR were mapped to visualize spatially-varying species-environment relationships. K-means cluster analyses based on the t-values of GWR local regression coefficients were used to characterize the distinct zones of ecological relationships.
Results: Geographically weighted regression resulted in a significant improvement over the GAM in goodness-of-fit and accuracy of model prediction. Results from the GWR revealed the magnitude and direction of environmental effects on Yellow Perch distribution changed among spatial locations. Consistent species-environment relationships were found in the west and east basins for adults. The different kinds of species-environment relationships found in the central management unit (MU) implied the variation of relationships at a scale finer than the MU.
Conclusions: This study draws attention to the importance of accounting for spatial nonstationarity in exploring species-environment relationships. The GWR results can provide support for identification of unique stocks and potential refinement of the current jurisdictional MU structure toward more ecologically relevant MUs for the sustainable management of Yellow Perch in Lake Erie.},
  language = {en},
  journal = {PeerJ},
  doi = {10/gf9mgb},
  author = {Liu, Changdong and Liu, Junchao and Jiao, Yan and Tang, Yanli and Reid, Kevin B.},
  month = jul,
  year = {2019},
  pages = {e7350},
  file = {/home/jkbest/Dropbox/Zotero/storage/2EC2KMWA/Liu et al. - 2019 - Exploring spatial nonstationary environmental effe.pdf},
  ids = {LiuEtAl2019a}
}

@article{MooreBarlow2011,
  title = {Bayesian State-Space Model of Fin Whale Abundance Trends from a 1991\textendash{}2008 Time Series of Line-Transect Surveys in the {{California Current}}},
  volume = {48},
  copyright = {\textcopyright{} 2011 The Authors. Journal of Applied Ecology \textcopyright{} 2011 British Ecological Society},
  issn = {1365-2664},
  abstract = {1. Estimating temporal trends in animal abundance is central to ecology and conservation, but obtaining useful trend estimates is challenging when animal detection rates vary across surveys (e.g. because of differences in observers or conditions). Methods exist for obtaining abundance estimates using capture\textendash{}recapture and distance sampling protocols, but only recently have some of these been extended to allow direct estimation of abundance trends when detection rates vary. Extensions to distance sampling for {$>$}2 surveys have not yet been demonstrated. 2. We demonstrate a Bayesian approach for estimating abundance and population trends, using a time series of line-transect data for endangered fin whales Balaenoptera physalus off the west coast of the United States. We use a hierarchical model to partition state and observation processes. Population density is modelled as a function of covariates and random process terms, while observed counts are modelled as an overdispersed Poisson process with rates estimated as a function of population density and detection probability, which is modelled using distance sampling theory. We used Deviance Information Criteria to make multi-model inference about abundance and trend estimates. 3. Bayesian posterior distributions for trend parameters provide strong evidence of increasing fin whale abundance in the California Current study area from 1991 to 2008, while individual abundance estimates during survey years were considerably more precise than previously reported estimates using the same data. Assuming no change in underlying population dynamics, we predict continued increases in fin whale numbers over the next decade. Our abundance projections account for both sampling error in parameter estimates and process variance in annual abundance about the mean trend. 4. Synthesis and applications. Bayesian hierarchical modelling offers numerous benefits for analysing animal abundance trends. In our case, these included its implicit handling of sampling covariance, flexibility to accommodate random effects and covariates, ability to compare trend models of different functional forms and ability to partition sampling and process error to make predictions. Ultimately, by placing distance sampling within a more general hierarchical framework, we obtained more precise abundance estimates and an inference about fin whale trends that would have otherwise been difficult.},
  language = {en},
  number = {5},
  journal = {Journal of Applied Ecology},
  doi = {10/fbkt4q},
  author = {Moore, Jeffrey E. and Barlow, Jay},
  year = {2011},
  keywords = {distance sampling,multi-model inference,Balaenoptera physalus,cetacean density,hierarchical modelling},
  pages = {1195-1205},
  file = {/home/jkbest/Dropbox/Zotero/storage/96IYUB2R/Moore and Barlow - 2011 - Bayesian state-space model of fin whale abundance trends from a 1991–2008 time.pdf}
}

@article{BestPunt2020,
  title = {Parameterizations for {{Bayesian}} State-Space Surplus Production Models},
  volume = {222},
  issn = {0165-7836},
  abstract = {Bayesian state-space surplus production models are commonly applied in fisheries stock assessment when the only information available is an index of relative abundance. However, even relatively simple models such as these can be computationally expensive to fit, and diagnosing poor fits can be difficult. The Stan software package provides an advanced Markov chain Monte Carlo sampler and diagnostics that are not available in other packages for fitting Bayesian models. Here the sampler diagnostics, efficiency, and posterior inferences are compared among multiple parameterizations of a state-space biomass dynamics model, using both Pella-Tomlinson and Schaefer dynamics. Two parameterizations that prevent predictions of negative biomass are introduced, one of which allows for errors in catch. None of the parameterizations used avoid diagnostic warnings using the default sampler parameter values. Choosing the appropriate parameterization of a model, and paying attention to these diagnostics can increase computational efficiency and make inferences more robust.},
  language = {en},
  journal = {Fisheries Research},
  doi = {10.1016/j.fishres.2019.105411},
  author = {Best, John K. and Punt, Andr{\'e} E.},
  month = feb,
  year = {2020},
  keywords = {diagnostics,Bayesian,Markov chain Monte Carlo,Stan,state-space,surplus production model},
  pages = {105411},
  file = {/home/jkbest/Dropbox/Zotero/storage/EWT28ELV/Best and Punt - 2020 - Parameterizations for Bayesian state-space surplus production models.pdf}
}


